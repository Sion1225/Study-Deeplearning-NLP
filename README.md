# Study-Deeplearning-NLP
### Study Deep learning &amp; Machine learning for NLP

This repository is for record my studies and make enable study anywhere for myself.      
   
These studies are based on [유원준/안상준, "딥 러닝을 이용한 자연어 처리 입문", 2022] plus [Saito Goki, "Deep Learning from Scratch"]. but is not same in all part.
And started from 22.09.27 .
   
Siwon Seo, Tokai-university

## Contents
### Text preprocessing
 - Tokenization
 - Cleaning & Normalization
 - Stemming & Lemmatization
 - Stopword
 - Integere Encoding
 - Padding
 - One-Hot Encoding
 - Splitting Data

### Language Model
 - Statistical Language Model
 - N-gram Language Model
 - Perplexity (PPL)

### Count based word Representation
 - Bag of Words (BoW)
 - Document-Term Matrix (DTM)
 - TF-IDF (Term Frequency-Inverse Document Frequency)

### Vector Similarity
 - Cosine Similarity
 - Euclidean distance, Jaccard similarity

### Machine Learning (Deep Learning basic)
 - Linear Regression
 - Automatic differentiation
 - Logistic Regression
 - Softmax Regression
 - etc..

### Deep Learning
 - Perceptron
 - Feed-Forward Neural Network (FFNN)
 - Fully-connected layer (FC)
 - Activation Function
 - Loss function
 - Batch Size
 - Optimizer
 - Back-Propagation
 - Overfitting
 - Gradient Vanishing & Exploding

### Recurrent Neural Network (RNN)
 - RNN
 - LSTM
 - GRU
 - BiLSTM (BiGRU)

### Word Embedding
 - Sparse Representation
 - Dense Representation & Word Embedding
 - Word2Vec
 - GloVe
 - FastText
 - ELMo

### CNN
 - CNN
 - 1D CNN
 - Character Embedding

### Tagging Task
 - Part of speech Tagging
 - Named Entity Recognition (NER)
 - BIO

__====================================__

### Subword Tokenizer
 - Byte Pair Encoding (BPE)
 - Sentence Piece
 - Subword Text Encoder

### Sequence to Sequence

### Attention Mechanism

### Transformer
