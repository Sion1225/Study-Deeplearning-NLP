{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ea79a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c20ed38",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The US Supreme Court has cleared the way for ex-President Donald Trump's tax forms to be released to a Democratic-controlled congressional committee.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49a1fc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'US', 'Supreme', 'Court', 'has', 'cleared', 'the', 'way', 'for', 'ex-President', 'Donald', 'Trump', \"'s\", 'tax', 'forms', 'to', 'be', 'released', 'to', 'a', 'Democratic-controlled', 'congressional', 'committee', '.']\n"
     ]
    }
   ],
   "source": [
    "tokenized = word_tokenize(text)\n",
    "print(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21615228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 1, 'to': 2, 'us': 3, 'supreme': 4, 'court': 5, 'has': 6, 'cleared': 7, 'way': 8, 'for': 9, 'ex': 10, 'president': 11, 'donald': 12, 'trump': 13, \"'s\": 14, 'tax': 15, 'forms': 16, 'be': 17, 'released': 18, 'a': 19, 'democratic': 20, 'controlled': 21, 'congressional': 22, 'committee': 23}\n",
      "OrderedDict([('the', 2), ('us', 1), ('supreme', 1), ('court', 1), ('has', 1), ('cleared', 1), ('way', 1), ('for', 1), ('ex', 1), ('president', 1), ('donald', 1), ('trump', 1), (\"'s\", 1), ('tax', 1), ('forms', 1), ('to', 2), ('be', 1), ('released', 1), ('a', 1), ('democratic', 1), ('controlled', 1), ('congressional', 1), ('committee', 1)])\n"
     ]
    }
   ],
   "source": [
    "tokenizer_integer = Tokenizer()\n",
    "tokenizer_integer.fit_on_texts(tokenized)\n",
    "print(tokenizer_integer.word_index)\n",
    "print(tokenizer_integer.word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726af05d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea20f4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bag_of_words(documnet):\n",
    "    document = documnet.replace('.', '')\n",
    "    document = document.lower()\n",
    "    tokenized_document = word_tokenize(document)\n",
    "    \n",
    "    word_to_index = {}\n",
    "    bow = []\n",
    "    \n",
    "    for word in tokenized_document:\n",
    "        if word not in word_to_index.keys():\n",
    "            word_to_index[word] = len(word_to_index)\n",
    "            #initialize BoW with value 1\n",
    "            bow.insert(len(word_to_index) - 1, 1)\n",
    "        else :\n",
    "            #index for be repeated\n",
    "            index = word_to_index.get(word)\n",
    "            #counting (plus 1)\n",
    "            bow[index] += 1\n",
    "            \n",
    "    return word_to_index, bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6896ccec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary : {'the': 0, 'us': 1, 'supreme': 2, 'court': 3, 'has': 4, 'cleared': 5, 'way': 6, 'for': 7, 'ex-president': 8, 'donald': 9, 'trump': 10, \"'s\": 11, 'tax': 12, 'forms': 13, 'to': 14, 'be': 15, 'released': 16, 'a': 17, 'democratic-controlled': 18, 'congressional': 19, 'committee': 20}\n",
      "bag of words vecotr : [2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "vocab, bow = build_bag_of_words(text)\n",
    "print('Vocabulary :',vocab)\n",
    "print('bag of words vecotr :', bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf558d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a6a7ae8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7872fa83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words vector : [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1]]\n",
      "vocabulary : {'the': 16, 'us': 19, 'supreme': 14, 'court': 5, 'has': 11, 'cleared': 1, 'way': 20, 'for': 9, 'ex': 8, 'president': 12, 'donald': 7, 'trump': 18, 'tax': 15, 'forms': 10, 'to': 17, 'be': 0, 'released': 13, 'democratic': 6, 'controlled': 4, 'congressional': 3, 'committee': 2}\n"
     ]
    }
   ],
   "source": [
    "corpus = [\"The US Supreme Court has cleared the way for ex-President Donald Trump's tax forms to be released to a Democratic-controlled congressional committee.\"]\n",
    "vector = CountVectorizer()\n",
    "corpus[0].lower()\n",
    "\n",
    "print('bag of words vector :', vector.fit_transform(corpus).toarray())\n",
    "print('vocabulary :',vector.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d84438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "78df6a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4fc7a295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words vector : [[1 1 1 1 1]]\n",
      "Vocabulary : {'family': 1, 'important': 2, 'thing': 4, 'it': 3, 'everything': 0}\n"
     ]
    }
   ],
   "source": [
    "text= [\"Family is not an important thing. It's everything.\"]\n",
    "vect = CountVectorizer(stop_words=[\"the\",\"a\",\"an\",\"is\",\"not\"])\n",
    "print('Bag of Words vector :', vect.fit_transform(text).toarray())\n",
    "print('Vocabulary :',vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8ca045f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words vector : [[1 1 1]]\n",
      "Vocabulary : {'family': 0, 'important': 1, 'thing': 2}\n"
     ]
    }
   ],
   "source": [
    "text = [\"Family is not an important thing. It's everything.\"]\n",
    "vect = CountVectorizer(stop_words=\"english\")\n",
    "print('Bag of Words vector :', vect.fit_transform(text).toarray())\n",
    "print('Vocabulary :',vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ba07024d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words vector : [[1 1 1 1]]\n",
      "Vocabulary : {'family': 1, 'important': 2, 'thing': 3, 'everything': 0}\n"
     ]
    }
   ],
   "source": [
    "text = [\"Family is not an important thing. It's everything.\"]\n",
    "stop_words = stopwords.words(\"english\")\n",
    "vect = CountVectorizer(stop_words=stop_words)\n",
    "print('Bag of Words vector :', vect.fit_transform(text).toarray())\n",
    "print('Vocabulary :',vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b0a5b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
