{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import urllib.request\n",
    "import zipfile\n",
    "from lxml import etree\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetXML = open('DataSet/ted_en-20160408.xml', 'r', encoding='UTF8')\n",
    "target_text = etree.parse(targetXML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nparse_text = \\'\\n\\'.join(target_text.xpath(\\'//content/text()\\'))\\ncontent_text = re.sub(r\\'\\\\([^)]*\\\\)\\', \\'\\', parse_text)\\nlc = len(content_text)\\nprint(lc)\\nlc=round(lc/8)\\nprint(lc)\\nct0 = content_text[0:lc]\\nct1 = content_text[lc:lc*2]\\nct2 = content_text[lc*2:lc*3]\\nct3 = content_text[lc*3:lc*4]\\nct4 = content_text[lc*4:lc*5]\\nct5 = content_text[lc*5:lc*6]\\nct6 = content_text[lc*6:lc*7]\\nct7 = content_text[lc*7:len(content_text)]\\n\\nimport multiprocessing\\n\\nif __name__ == \"__main__\":\\n    # main process\\n    proc = multiprocessing.current_process()\\n    print(proc.name)\\n    print(proc.pid)\\n\\n    pool = multiprocessing.Pool(processes=8)\\n    \\n    sent_text = pool.map(sent_tokenize,[ct0,ct1,ct2,ct3,ct4,ct5,ct6,ct7])\\n    \\n    pool.close()\\n    pool.join()\\n    \\ndef normalize (sent_text) :\\n    normalized_text = []\\n    for string in sent_text:\\n        tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\\n        normalized_text.append(tokens)\\n\\n    result = [word_tokenize(sentence) for sentence in normalized_text]\\n    \\n    return result\\n    \\nif __name__ == \"__main__\" :\\n    proc = multiprocessing.current_process()\\n    print(proc.name)\\n    print(proc.pid)\\n    \\n    pool = multiprocessing.Pool(processes=8)\\n    \\n    normalized_text = pool.map(normalize, sent_text)\\n    \\n    pool.close()\\n    pool.join()\\n    \\nnormalized_text = sum(normalized_text,[])\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n",
    "content_text = re.sub(r'\\([^)]*\\)', '', parse_text)\n",
    "lc = len(content_text)\n",
    "print(lc)\n",
    "lc=round(lc/8)\n",
    "print(lc)\n",
    "ct0 = content_text[0:lc]\n",
    "ct1 = content_text[lc:lc*2]\n",
    "ct2 = content_text[lc*2:lc*3]\n",
    "ct3 = content_text[lc*3:lc*4]\n",
    "ct4 = content_text[lc*4:lc*5]\n",
    "ct5 = content_text[lc*5:lc*6]\n",
    "ct6 = content_text[lc*6:lc*7]\n",
    "ct7 = content_text[lc*7:len(content_text)]\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # main process\n",
    "    proc = multiprocessing.current_process()\n",
    "    print(proc.name)\n",
    "    print(proc.pid)\n",
    "\n",
    "    pool = multiprocessing.Pool(processes=8)\n",
    "    \n",
    "    sent_text = pool.map(sent_tokenize,[ct0,ct1,ct2,ct3,ct4,ct5,ct6,ct7])\n",
    "    \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "def normalize (sent_text) :\n",
    "    normalized_text = []\n",
    "    for string in sent_text:\n",
    "        tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n",
    "        normalized_text.append(tokens)\n",
    "\n",
    "    result = [word_tokenize(sentence) for sentence in normalized_text]\n",
    "    \n",
    "    return result\n",
    "    \n",
    "if __name__ == \"__main__\" :\n",
    "    proc = multiprocessing.current_process()\n",
    "    print(proc.name)\n",
    "    print(proc.pid)\n",
    "    \n",
    "    pool = multiprocessing.Pool(processes=8)\n",
    "    \n",
    "    normalized_text = pool.map(normalize, sent_text)\n",
    "    \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "normalized_text = sum(normalized_text,[])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n",
    "content_text = re.sub(r'\\([^)]*\\)', '', parse_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_text = sent_tokenize(content_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-30 18:20:33,711\tINFO worker.py:1538 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.5</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.2.0</b></td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.8.5', ray_version='2.2.0', ray_commit='b6af0887ee5f2e460202133791ad941a41f15beb', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': 'tcp://127.0.0.1:62022', 'raylet_socket_name': 'tcp://127.0.0.1:64299', 'webui_url': '', 'session_dir': 'C:\\\\Users\\\\visio\\\\AppData\\\\Local\\\\Temp\\\\ray\\\\session_2023-01-30_18-20-29_259222_28652', 'metrics_export_port': 62237, 'gcs_address': '127.0.0.1:62218', 'address': '127.0.0.1:62218', 'dashboard_agent_listen_port': 52365, 'node_id': 'f9138f56774f15f83183cd8fe65af20c4ed494ee4b5498448fc1bc03'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def normalize (sent_text) :\n",
    "    normalized_text = []\n",
    "    for string in sent_text:\n",
    "        tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n",
    "        normalized_text.append(tokens)\n",
    "\n",
    "    result = [word_tokenize(sentence) for sentence in normalized_text]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = normalize.remote(sent_text)\n",
    "result = ray.get(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of samples :  273424\n"
     ]
    }
   ],
   "source": [
    "print(\"Count of samples : \",len(result))\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new']\n",
      "['to', 'me', 'the', 'real', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', 'exploration', 'and', 'exploitation']\n",
      "['both', 'are', 'necessary', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing']\n",
      "['consider', 'facit']\n",
      "['i', 'm', 'actually', 'old', 'enough', 'to', 'remember', 'them']\n"
     ]
    }
   ],
   "source": [
    "for line in result[:5]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss function = V Sigma (m,n=1) f(Xmn)(wm^t wn + bm + bn - logXmn)^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glove import Corpus, Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus()\n",
    "\n",
    "corpus.fit(result, window=5)\n",
    "glove = Glove(no_components=100, learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 20 training epochs with 16 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n"
     ]
    }
   ],
   "source": [
    "glove.fit(corpus.matrix, epochs=20, no_threads=16, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove.add_dictionary(corpus.dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 0.9661888168051073), ('guy', 0.8924342444397232), ('girl', 0.8667156211245537), ('young', 0.8455951335860868)]\n"
     ]
    }
   ],
   "source": [
    "print(glove.most_similar(\"man\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('harvard', 0.8875913021262088), ('mit', 0.8622224406564739), ('stanford', 0.8390199683602717), ('cambridge', 0.8339740474783915)]\n"
     ]
    }
   ],
   "source": [
    "print(glove.most_similar(\"university\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
