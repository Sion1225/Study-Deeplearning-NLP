{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 70000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def preprocess_sentence(sent) :\n",
    "    sent = to_ascii(sent.lower())\n",
    "    sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
    "    sent = re.sub(r\"[^a-zA-Z!.?,]+\", r\" \", sent)\n",
    "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
    "    \n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aab , ?d test .'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_sentence(\"Aab,?d ㄷ   test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocessed_data() :\n",
    "    encoder_input, decoder_input, decoder_target = [], [], []\n",
    "    \n",
    "    with open(\"DataSet/spa.txt\",\"r\") as lines :\n",
    "        for i, line in enumerate(lines) :\n",
    "            src_line, tar_line, _ = line.strip().split('\\t')\n",
    "            src_line = [w for w in preprocess_sentence(src_line).split()]\n",
    "            \n",
    "            tar_line = preprocess_sentence(tar_line)\n",
    "            tar_line_in = [w for w in (\"<sos> \" + tar_line).split()]\n",
    "            tar_line_out = [w for w in (tar_line + \" <eos>\").split()]\n",
    "            \n",
    "            encoder_input.append(src_line)\n",
    "            decoder_input.append(tar_line_in)\n",
    "            decoder_target.append(tar_line_out)\n",
    "            \n",
    "            if i==num_samples-1 :\n",
    "                break\n",
    "                \n",
    "    return encoder_input, decoder_input, decoder_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_en_in, sents_spa_in, sents_spa_out = load_preprocessed_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['go', '.'], ['go', '.'], ['go', '.'], ['go', '.'], ['hi', '.'], ['hi', '.'], ['run', '!']]\n",
      "[['<sos>', 've', '.'], ['<sos>', 'vete', '.'], ['<sos>', 'vaya', '.'], ['<sos>', 'v', 'yase', '.'], ['<sos>', 'hola', '.'], ['<sos>', 'hola'], ['<sos>', 'corre', '!']]\n",
      "[['ve', '.', '<eos>'], ['vete', '.', '<eos>'], ['vaya', '.', '<eos>'], ['v', 'yase', '.', '<eos>'], ['hola', '.', '<eos>'], ['hola', '<eos>'], ['corre', '!', '<eos>']]\n"
     ]
    }
   ],
   "source": [
    "print(sents_en_in[:7])\n",
    "print(sents_spa_in[:7])\n",
    "print(sents_spa_out[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = Tokenizer(filters=\"\", lower=False)\n",
    "tokenizer_en.fit_on_texts(sents_en_in)\n",
    "encoder_input = tokenizer_en.texts_to_sequences(sents_en_in)\n",
    "encoder_input = pad_sequences(encoder_input, padding=\"post\")\n",
    "\n",
    "tokenizer_spa = Tokenizer(filters=\"\", lower=False)\n",
    "tokenizer_spa.fit_on_texts(sents_spa_in)\n",
    "tokenizer_spa.fit_on_texts(sents_spa_out)\n",
    "\n",
    "decoder_input = tokenizer_spa.texts_to_sequences(sents_spa_in)\n",
    "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
    "decoder_target = tokenizer_spa.texts_to_sequences(sents_spa_out)\n",
    "decoder_target = pad_sequences(decoder_target, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 11)\n",
      "(70000, 18)\n",
      "(70000, 18)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input.shape)\n",
    "print(decoder_input.shape)\n",
    "print(decoder_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of english voca set: 8112\n",
      "Size of spanish voca set: 14700\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(tokenizer_en.word_index)+1\n",
    "tar_vocab_size = len(tokenizer_spa.word_index)+1\n",
    "print(\"Size of english voca set:\",src_vocab_size)\n",
    "print(\"Size of spanish voca set:\",tar_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_to_index = tokenizer_en.word_index\n",
    "index_to_src = tokenizer_en.index_word\n",
    "tar_to_index = tokenizer_spa.word_index\n",
    "index_to_tar = tokenizer_spa.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random sequence : [31046 13381 68641 ... 46009 45508 33703]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(\"random sequence :\",indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  18 1440    8  651    1    0    0    0    0    0    0]\n",
      "[   2   65 1805    8 2197    1    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "[  65 1805    8 2197    1    3    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input[0])\n",
    "print(decoder_input[0])\n",
    "print(decoder_target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test data :  7000\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(num_samples*0.1)\n",
    "print(\"Number of test data : \",n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63000, 11)\n",
      "(7000, 11)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_train.shape)\n",
    "print(encoder_input_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 64\n",
    "hidden_units = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb = Embedding(src_vocab_size, embedding_dim)(encoder_inputs)\n",
    "enc_masking = Masking(mask_value=0)(enc_emb)\n",
    "encoder_lstm = LSTM(hidden_units, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoder\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(tar_vocab_size, hidden_units)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "dec_masking = Masking(mask_value=0)(dec_emb)\n",
    "\n",
    "decoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_masking, initial_state=encoder_states)\n",
    "\n",
    "decoder_dense = Dense(tar_vocab_size, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model compile\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "492/493 [============================>.] - ETA: 0s - loss: 2.7931 - accuracy: 0.6508\n",
      "Epoch 1: val_accuracy improved from -inf to 0.73791, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 18s 28ms/step - loss: 2.7928 - accuracy: 0.6508 - val_loss: 1.8676 - val_accuracy: 0.7379\n",
      "Epoch 2/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 1.7522 - accuracy: 0.7447\n",
      "Epoch 2: val_accuracy improved from 0.73791 to 0.75237, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 1.7522 - accuracy: 0.7447 - val_loss: 1.6562 - val_accuracy: 0.7524\n",
      "Epoch 3/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 1.5883 - accuracy: 0.7578\n",
      "Epoch 3: val_accuracy improved from 0.75237 to 0.77247, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 1.5883 - accuracy: 0.7578 - val_loss: 1.5209 - val_accuracy: 0.7725\n",
      "Epoch 4/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 1.4479 - accuracy: 0.7808\n",
      "Epoch 4: val_accuracy improved from 0.77247 to 0.78736, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 1.4479 - accuracy: 0.7808 - val_loss: 1.4060 - val_accuracy: 0.7874\n",
      "Epoch 5/100\n",
      "492/493 [============================>.] - ETA: 0s - loss: 1.3322 - accuracy: 0.7931\n",
      "Epoch 5: val_accuracy improved from 0.78736 to 0.79850, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 1.3322 - accuracy: 0.7931 - val_loss: 1.3105 - val_accuracy: 0.7985\n",
      "Epoch 6/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 1.2356 - accuracy: 0.8034\n",
      "Epoch 6: val_accuracy improved from 0.79850 to 0.80704, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 1.2356 - accuracy: 0.8034 - val_loss: 1.2398 - val_accuracy: 0.8070\n",
      "Epoch 7/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 1.1562 - accuracy: 0.8129\n",
      "Epoch 7: val_accuracy improved from 0.80704 to 0.81434, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 1.1562 - accuracy: 0.8129 - val_loss: 1.1800 - val_accuracy: 0.8143\n",
      "Epoch 8/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 1.0886 - accuracy: 0.8206\n",
      "Epoch 8: val_accuracy improved from 0.81434 to 0.82011, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 1.0886 - accuracy: 0.8206 - val_loss: 1.1321 - val_accuracy: 0.8201\n",
      "Epoch 9/100\n",
      "492/493 [============================>.] - ETA: 0s - loss: 1.0289 - accuracy: 0.8274\n",
      "Epoch 9: val_accuracy improved from 0.82011 to 0.82470, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 1.0288 - accuracy: 0.8274 - val_loss: 1.0905 - val_accuracy: 0.8247\n",
      "Epoch 10/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.9752 - accuracy: 0.8335\n",
      "Epoch 10: val_accuracy improved from 0.82470 to 0.82867, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 0.9752 - accuracy: 0.8335 - val_loss: 1.0533 - val_accuracy: 0.8287\n",
      "Epoch 11/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.9264 - accuracy: 0.8391\n",
      "Epoch 11: val_accuracy improved from 0.82867 to 0.83257, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 0.9264 - accuracy: 0.8391 - val_loss: 1.0199 - val_accuracy: 0.8326\n",
      "Epoch 12/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.8817 - accuracy: 0.8442\n",
      "Epoch 12: val_accuracy improved from 0.83257 to 0.83616, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 0.8817 - accuracy: 0.8442 - val_loss: 0.9934 - val_accuracy: 0.8362\n",
      "Epoch 13/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.8397 - accuracy: 0.8490\n",
      "Epoch 13: val_accuracy improved from 0.83616 to 0.83880, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 0.8397 - accuracy: 0.8490 - val_loss: 0.9679 - val_accuracy: 0.8388\n",
      "Epoch 14/100\n",
      "492/493 [============================>.] - ETA: 0s - loss: 0.8003 - accuracy: 0.8539\n",
      "Epoch 14: val_accuracy improved from 0.83880 to 0.84301, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 25ms/step - loss: 0.8003 - accuracy: 0.8539 - val_loss: 0.9431 - val_accuracy: 0.8430\n",
      "Epoch 15/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.7633 - accuracy: 0.8587\n",
      "Epoch 15: val_accuracy improved from 0.84301 to 0.84567, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 0.7633 - accuracy: 0.8587 - val_loss: 0.9240 - val_accuracy: 0.8457\n",
      "Epoch 16/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.7296 - accuracy: 0.8630\n",
      "Epoch 16: val_accuracy improved from 0.84567 to 0.84848, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 25ms/step - loss: 0.7296 - accuracy: 0.8630 - val_loss: 0.9062 - val_accuracy: 0.8485\n",
      "Epoch 17/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.6982 - accuracy: 0.8672\n",
      "Epoch 17: val_accuracy improved from 0.84848 to 0.85043, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 25ms/step - loss: 0.6982 - accuracy: 0.8672 - val_loss: 0.8926 - val_accuracy: 0.8504\n",
      "Epoch 18/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.6687 - accuracy: 0.8710\n",
      "Epoch 18: val_accuracy improved from 0.85043 to 0.85297, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 25ms/step - loss: 0.6687 - accuracy: 0.8710 - val_loss: 0.8772 - val_accuracy: 0.8530\n",
      "Epoch 19/100\n",
      "492/493 [============================>.] - ETA: 0s - loss: 0.6415 - accuracy: 0.8748\n",
      "Epoch 19: val_accuracy improved from 0.85297 to 0.85502, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 25ms/step - loss: 0.6415 - accuracy: 0.8748 - val_loss: 0.8654 - val_accuracy: 0.8550\n",
      "Epoch 20/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.6158 - accuracy: 0.8782\n",
      "Epoch 20: val_accuracy improved from 0.85502 to 0.85628, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 25ms/step - loss: 0.6158 - accuracy: 0.8782 - val_loss: 0.8553 - val_accuracy: 0.8563\n",
      "Epoch 21/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.5918 - accuracy: 0.8815\n",
      "Epoch 21: val_accuracy improved from 0.85628 to 0.85848, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 25ms/step - loss: 0.5918 - accuracy: 0.8815 - val_loss: 0.8471 - val_accuracy: 0.8585\n",
      "Epoch 22/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.5694 - accuracy: 0.8848\n",
      "Epoch 22: val_accuracy improved from 0.85848 to 0.85906, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 25ms/step - loss: 0.5694 - accuracy: 0.8848 - val_loss: 0.8384 - val_accuracy: 0.8591\n",
      "Epoch 23/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.5483 - accuracy: 0.8880\n",
      "Epoch 23: val_accuracy improved from 0.85906 to 0.86016, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 25ms/step - loss: 0.5483 - accuracy: 0.8880 - val_loss: 0.8326 - val_accuracy: 0.8602\n",
      "Epoch 24/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.5287 - accuracy: 0.8907\n",
      "Epoch 24: val_accuracy improved from 0.86016 to 0.86145, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 25ms/step - loss: 0.5287 - accuracy: 0.8907 - val_loss: 0.8260 - val_accuracy: 0.8615\n",
      "Epoch 25/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.5100 - accuracy: 0.8937\n",
      "Epoch 25: val_accuracy improved from 0.86145 to 0.86244, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 25ms/step - loss: 0.5100 - accuracy: 0.8937 - val_loss: 0.8206 - val_accuracy: 0.8624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.4922 - accuracy: 0.8965\n",
      "Epoch 26: val_accuracy improved from 0.86244 to 0.86288, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 0.4922 - accuracy: 0.8965 - val_loss: 0.8158 - val_accuracy: 0.8629\n",
      "Epoch 27/100\n",
      "492/493 [============================>.] - ETA: 0s - loss: 0.4756 - accuracy: 0.8992\n",
      "Epoch 27: val_accuracy improved from 0.86288 to 0.86402, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 0.4756 - accuracy: 0.8992 - val_loss: 0.8122 - val_accuracy: 0.8640\n",
      "Epoch 28/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.4598 - accuracy: 0.9018\n",
      "Epoch 28: val_accuracy improved from 0.86402 to 0.86498, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 25ms/step - loss: 0.4598 - accuracy: 0.9018 - val_loss: 0.8066 - val_accuracy: 0.8650\n",
      "Epoch 29/100\n",
      "492/493 [============================>.] - ETA: 0s - loss: 0.4450 - accuracy: 0.9045\n",
      "Epoch 29: val_accuracy improved from 0.86498 to 0.86563, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 0.4450 - accuracy: 0.9044 - val_loss: 0.8034 - val_accuracy: 0.8656\n",
      "Epoch 30/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.4310 - accuracy: 0.9070\n",
      "Epoch 30: val_accuracy improved from 0.86563 to 0.86607, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 0.4310 - accuracy: 0.9070 - val_loss: 0.8013 - val_accuracy: 0.8661\n",
      "Epoch 31/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.4177 - accuracy: 0.9093\n",
      "Epoch 31: val_accuracy did not improve from 0.86607\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 0.4177 - accuracy: 0.9093 - val_loss: 0.8009 - val_accuracy: 0.8657\n",
      "Epoch 32/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.4053 - accuracy: 0.9119\n",
      "Epoch 32: val_accuracy improved from 0.86607 to 0.86654, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 0.4053 - accuracy: 0.9119 - val_loss: 0.7982 - val_accuracy: 0.8665\n",
      "Epoch 33/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.3931 - accuracy: 0.9142\n",
      "Epoch 33: val_accuracy improved from 0.86654 to 0.86756, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 0.3931 - accuracy: 0.9142 - val_loss: 0.7954 - val_accuracy: 0.8676\n",
      "Epoch 34/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.3818 - accuracy: 0.9164\n",
      "Epoch 34: val_accuracy improved from 0.86756 to 0.86808, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 0.3818 - accuracy: 0.9164 - val_loss: 0.7960 - val_accuracy: 0.8681\n",
      "Epoch 35/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.3710 - accuracy: 0.9186\n",
      "Epoch 35: val_accuracy improved from 0.86808 to 0.86870, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 0.3710 - accuracy: 0.9186 - val_loss: 0.7935 - val_accuracy: 0.8687\n",
      "Epoch 36/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.3611 - accuracy: 0.9204\n",
      "Epoch 36: val_accuracy improved from 0.86870 to 0.86897, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 0.3611 - accuracy: 0.9204 - val_loss: 0.7934 - val_accuracy: 0.8690\n",
      "Epoch 37/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.3515 - accuracy: 0.9224\n",
      "Epoch 37: val_accuracy improved from 0.86897 to 0.86984, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 0.3515 - accuracy: 0.9224 - val_loss: 0.7922 - val_accuracy: 0.8698\n",
      "Epoch 38/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.3424 - accuracy: 0.9242\n",
      "Epoch 38: val_accuracy did not improve from 0.86984\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 0.3424 - accuracy: 0.9242 - val_loss: 0.7928 - val_accuracy: 0.8698\n",
      "Epoch 39/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.3340 - accuracy: 0.9257\n",
      "Epoch 39: val_accuracy improved from 0.86984 to 0.87075, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 0.3340 - accuracy: 0.9257 - val_loss: 0.7925 - val_accuracy: 0.8708\n",
      "Epoch 40/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.3255 - accuracy: 0.9275\n",
      "Epoch 40: val_accuracy did not improve from 0.87075\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 0.3255 - accuracy: 0.9275 - val_loss: 0.7948 - val_accuracy: 0.8703\n",
      "Epoch 41/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.3175 - accuracy: 0.9291\n",
      "Epoch 41: val_accuracy improved from 0.87075 to 0.87101, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 0.3175 - accuracy: 0.9291 - val_loss: 0.7940 - val_accuracy: 0.8710\n",
      "Epoch 42/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.3099 - accuracy: 0.9307\n",
      "Epoch 42: val_accuracy did not improve from 0.87101\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 0.3099 - accuracy: 0.9307 - val_loss: 0.7961 - val_accuracy: 0.8709\n",
      "Epoch 43/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.3026 - accuracy: 0.9322\n",
      "Epoch 43: val_accuracy improved from 0.87101 to 0.87160, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 0.3026 - accuracy: 0.9322 - val_loss: 0.7959 - val_accuracy: 0.8716\n",
      "Epoch 44/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.2959 - accuracy: 0.9336\n",
      "Epoch 44: val_accuracy improved from 0.87160 to 0.87199, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 25ms/step - loss: 0.2959 - accuracy: 0.9336 - val_loss: 0.7991 - val_accuracy: 0.8720\n",
      "Epoch 45/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.2893 - accuracy: 0.9349\n",
      "Epoch 45: val_accuracy did not improve from 0.87199\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 0.2893 - accuracy: 0.9349 - val_loss: 0.7999 - val_accuracy: 0.8717\n",
      "Epoch 46/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.2832 - accuracy: 0.9359\n",
      "Epoch 46: val_accuracy did not improve from 0.87199\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 0.2832 - accuracy: 0.9359 - val_loss: 0.7992 - val_accuracy: 0.8718\n",
      "Epoch 47/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.2770 - accuracy: 0.9371\n",
      "Epoch 47: val_accuracy improved from 0.87199 to 0.87230, saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 12s 25ms/step - loss: 0.2770 - accuracy: 0.9371 - val_loss: 0.8033 - val_accuracy: 0.8723\n",
      "Epoch 48/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.2712 - accuracy: 0.9384\n",
      "Epoch 48: val_accuracy did not improve from 0.87230\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 0.2712 - accuracy: 0.9384 - val_loss: 0.8065 - val_accuracy: 0.8718\n",
      "Epoch 49/100\n",
      "492/493 [============================>.] - ETA: 0s - loss: 0.2658 - accuracy: 0.9393\n",
      "Epoch 49: val_accuracy did not improve from 0.87230\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 0.2658 - accuracy: 0.9393 - val_loss: 0.8081 - val_accuracy: 0.8718\n",
      "Epoch 50/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.2609 - accuracy: 0.9403\n",
      "Epoch 50: val_accuracy did not improve from 0.87230\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 0.2609 - accuracy: 0.9403 - val_loss: 0.8111 - val_accuracy: 0.8715\n",
      "Epoch 51/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.2556 - accuracy: 0.9413\n",
      "Epoch 51: val_accuracy did not improve from 0.87230\n",
      "493/493 [==============================] - 12s 24ms/step - loss: 0.2556 - accuracy: 0.9413 - val_loss: 0.8105 - val_accuracy: 0.8721\n",
      "Epoch 51: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1825ae81610>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model training\n",
    "es = EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", verbose=1, patience=4)\n",
    "mc = ModelCheckpoint(\"Models/best_Seq2seq_model.h5\", monitor=\"val_accuracy\", mode=\"max\", verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), batch_size=128, epochs=100, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"Models/best_Seq2seq_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder\n",
    "encoder_model = Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoder\n",
    "decoder_state_input_h = Input(shape=(hidden_units,))\n",
    "decoder_state_input_c = Input(shape=(hidden_units,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs) #Shared layer\n",
    "\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Activating Decoder\n",
    "def decode_sequence(input_seq) :\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0,0] = tar_to_index[\"<sos>\"]\n",
    "    \n",
    "    decoded_sentence = ''\n",
    "    stop_condition = True\n",
    "    \n",
    "    while stop_condition :\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        \n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :]) #가장 마지막 행 전체\n",
    "        sampled_char = index_to_tar[sampled_token_index]\n",
    "        \n",
    "        decoded_sentence += ' ' + sampled_char\n",
    "        \n",
    "        if (sampled_char == '<eos>' or len(decoded_sentence) > 50) :\n",
    "            stop_condition = False\n",
    "        \n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0,0] = sampled_token_index\n",
    "        \n",
    "        sates_value = [h, c]\n",
    "        \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_to_src(input_seq):\n",
    "    sentence = ''\n",
    "    for encoded_word in input_seq:\n",
    "        if(encoded_word != 0):\n",
    "            sentence = sentence + index_to_src[encoded_word] + ' '\n",
    "            \n",
    "    return sentence\n",
    "\n",
    "def seq_to_tar(input_seq):\n",
    "    sentence = ''\n",
    "    for encoded_word in input_seq:\n",
    "        if(encoded_word != 0 and encoded_word != tar_to_index['<sos>'] and encoded_word != tar_to_index['<eos>']):\n",
    "            sentence = sentence + index_to_tar[encoded_word] + ' '\n",
    "            \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Input sentence : i wish he were on our team . \n",
      "Correct sentence : desear a que l estuviera en nuestro equipo . \n",
      "Output sentence : desear a lo hubiera poder dejar que puedo que \n",
      "--------------------------------------------------\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Input sentence : what happened next ? \n",
      "Correct sentence : qu pas a continuaci n ? \n",
      "Output sentence : qu pas a qu pas a qu pas a qu pas a qu pas a q\n",
      "--------------------------------------------------\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Input sentence : is tom lucid ? \n",
      "Correct sentence : tom es l cido ? \n",
      "Output sentence : tom es tom es tom es tom es tom es tom es tom e\n",
      "--------------------------------------------------\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Input sentence : tom has two jobs . \n",
      "Correct sentence : tom tiene dos trabajos . \n",
      "Output sentence : tom tiene tom tiene tom tiene tom tiene tom tien\n",
      "--------------------------------------------------\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Input sentence : would you like to watch tv ? \n",
      "Correct sentence : te gustar a ver la televisi n ? \n",
      "Output sentence : te gustar a gustar a gustar a gustar a gustar a g\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [3, 100, 300, 500, 2001]:\n",
    "    input_seq = encoder_input_train[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "\n",
    "    print(\"Input sentence :\",seq_to_src(encoder_input_train[seq_index]))\n",
    "    print(\"Correct sentence :\",seq_to_tar(decoder_input_train[seq_index]))\n",
    "    print(\"Output sentence :\",decoded_sentence[1:-5])\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
