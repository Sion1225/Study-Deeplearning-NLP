{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 70000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sent) :\n",
    "    sent = sent.lower()\n",
    "    sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
    "    sent = re.sub(r\"[^a-zA-Z!.?,]+\", r\" \", sent)\n",
    "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
    "    \n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aab , ?d test .'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_sentence(\"Aab,?d ㄷ   test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocessed_data() :\n",
    "    encoder_input, decoder_input, decoder_target = [], [], []\n",
    "    \n",
    "    with open(\"DataSet/spa.txt\",\"r\") as lines :\n",
    "        for i, line in enumerate(lines) :\n",
    "            src_line, tar_line, _ = line.strip().split('\\t')\n",
    "            src_line = [w for w in preprocess_sentence(src_line).split()]\n",
    "            \n",
    "            tar_line = preprocess_sentence(tar_line)\n",
    "            tar_line_in = [w for w in (\"<sos> \" + tar_line).split()]\n",
    "            tar_line_out = [w for w in (tar_line + \" <eos>\").split()]\n",
    "            \n",
    "            encoder_input.append(src_line)\n",
    "            decoder_input.append(tar_line_in)\n",
    "            decoder_target.append(tar_line_out)\n",
    "            \n",
    "            if i==num_samples-1 :\n",
    "                break\n",
    "                \n",
    "    return encoder_input, decoder_input, decoder_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_en_in, sents_spa_in, sents_spa_out = load_preprocessed_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['go', '.'], ['go', '.'], ['go', '.'], ['go', '.'], ['hi', '.'], ['hi', '.'], ['run', '!']]\n",
      "[['<sos>', 've', '.'], ['<sos>', 'vete', '.'], ['<sos>', 'vaya', '.'], ['<sos>', 'v', 'yase', '.'], ['<sos>', 'hola', '.'], ['<sos>', 'hola'], ['<sos>', 'corre', '!']]\n",
      "[['ve', '.', '<eos>'], ['vete', '.', '<eos>'], ['vaya', '.', '<eos>'], ['v', 'yase', '.', '<eos>'], ['hola', '.', '<eos>'], ['hola', '<eos>'], ['corre', '!', '<eos>']]\n"
     ]
    }
   ],
   "source": [
    "print(sents_en_in[:7])\n",
    "print(sents_spa_in[:7])\n",
    "print(sents_spa_out[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = Tokenizer(filters=\"\", lower=False)\n",
    "tokenizer_en.fit_on_texts(sents_en_in)\n",
    "encoder_input = tokenizer_en.texts_to_sequences(sents_en_in)\n",
    "encoder_input = pad_sequences(encoder_input, padding=\"post\")\n",
    "\n",
    "tokenizer_spa = Tokenizer(filters=\"\", lower=False)\n",
    "tokenizer_spa.fit_on_texts(sents_spa_in)\n",
    "tokenizer_spa.fit_on_texts(sents_spa_out)\n",
    "\n",
    "decoder_input = tokenizer_spa.texts_to_sequences(sents_spa_in)\n",
    "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
    "decoder_target = tokenizer_spa.texts_to_sequences(sents_spa_out)\n",
    "decoder_target = pad_sequences(decoder_target, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 11)\n",
      "(70000, 18)\n",
      "(70000, 18)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input.shape)\n",
    "print(decoder_input.shape)\n",
    "print(decoder_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of english voca set: 8111\n",
      "Size of spanish voca set: 14689\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(tokenizer_en.word_index)+1\n",
    "tar_vocab_size = len(tokenizer_spa.word_index)+1\n",
    "print(\"Size of english voca set:\",src_vocab_size)\n",
    "print(\"Size of spanish voca set:\",tar_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_to_index = tokenizer_en.word_index\n",
    "index_to_src = tokenizer_en.index_word\n",
    "tar_to_index = tokenizer_spa.word_index\n",
    "index_to_tar = tokenizer_spa.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random sequence : [38377 60914 53285 ... 32637 22354 53349]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(\"random sequence :\",indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2  22  10  33  18 470   1   0   0   0   0]\n",
      "[  2   7  15  50  65 465  17   1   0   0   0   0   0   0   0   0   0   0]\n",
      "[  7  15  50  65 465  17   1   3   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input[0])\n",
    "print(decoder_input[0])\n",
    "print(decoder_target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test data :  7000\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(num_samples*0.1)\n",
    "print(\"Number of test data : \",n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63000, 11)\n",
      "(7000, 11)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_train.shape)\n",
    "print(encoder_input_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 64\n",
    "hidden_units = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb = Embedding(src_vocab_size, embedding_dim)(encoder_inputs)\n",
    "enc_masking = Masking(mask_value=0)(enc_emb)\n",
    "encoder_lstm = LSTM(hidden_units, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoder\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(tar_vocab_size, hidden_units)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "dec_masking = Masking(mask_value=0)(dec_emb)\n",
    "\n",
    "decoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_masking, initial_state=encoder_states)\n",
    "\n",
    "decoder_dense = Dense(tar_vocab_size, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model compile\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 2.7547 - accuracy: 0.6645\n",
      "Epoch 1: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 32s 40ms/step - loss: 2.7547 - accuracy: 0.6645 - val_loss: 1.8191 - val_accuracy: 0.7422\n",
      "Epoch 2/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 1.7253 - accuracy: 0.7450\n",
      "Epoch 2: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 16s 33ms/step - loss: 1.7253 - accuracy: 0.7450 - val_loss: 1.6492 - val_accuracy: 0.7510\n",
      "Epoch 3/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 1.5891 - accuracy: 0.7558\n",
      "Epoch 3: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 16s 33ms/step - loss: 1.5891 - accuracy: 0.7558 - val_loss: 1.5324 - val_accuracy: 0.7643\n",
      "Epoch 4/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 1.4503 - accuracy: 0.7769\n",
      "Epoch 4: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 16s 33ms/step - loss: 1.4503 - accuracy: 0.7769 - val_loss: 1.3958 - val_accuracy: 0.7864\n",
      "Epoch 5/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 1.3222 - accuracy: 0.7924\n",
      "Epoch 5: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 16s 33ms/step - loss: 1.3222 - accuracy: 0.7924 - val_loss: 1.2994 - val_accuracy: 0.7963\n",
      "Epoch 6/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 1.2242 - accuracy: 0.8035\n",
      "Epoch 6: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 16s 33ms/step - loss: 1.2242 - accuracy: 0.8035 - val_loss: 1.2245 - val_accuracy: 0.8067\n",
      "Epoch 7/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 1.1467 - accuracy: 0.8128\n",
      "Epoch 7: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 16s 33ms/step - loss: 1.1467 - accuracy: 0.8128 - val_loss: 1.1699 - val_accuracy: 0.8131\n",
      "Epoch 8/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 1.0824 - accuracy: 0.8202\n",
      "Epoch 8: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 16s 33ms/step - loss: 1.0824 - accuracy: 0.8202 - val_loss: 1.1219 - val_accuracy: 0.8198\n",
      "Epoch 9/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 1.0249 - accuracy: 0.8270\n",
      "Epoch 9: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 16s 33ms/step - loss: 1.0249 - accuracy: 0.8270 - val_loss: 1.0804 - val_accuracy: 0.8242\n",
      "Epoch 10/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.9710 - accuracy: 0.8337\n",
      "Epoch 10: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 17s 34ms/step - loss: 0.9710 - accuracy: 0.8337 - val_loss: 1.0434 - val_accuracy: 0.8300\n",
      "Epoch 11/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.9216 - accuracy: 0.8397\n",
      "Epoch 11: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 16s 33ms/step - loss: 0.9216 - accuracy: 0.8397 - val_loss: 1.0112 - val_accuracy: 0.8340\n",
      "Epoch 12/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.8766 - accuracy: 0.8451\n",
      "Epoch 12: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 16s 33ms/step - loss: 0.8766 - accuracy: 0.8451 - val_loss: 0.9836 - val_accuracy: 0.8379\n",
      "Epoch 13/100\n",
      "492/493 [============================>.] - ETA: 0s - loss: 0.8347 - accuracy: 0.8503\n",
      "Epoch 13: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 16s 33ms/step - loss: 0.8347 - accuracy: 0.8503 - val_loss: 0.9578 - val_accuracy: 0.8410\n",
      "Epoch 14/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.7959 - accuracy: 0.8548\n",
      "Epoch 14: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 16s 33ms/step - loss: 0.7959 - accuracy: 0.8548 - val_loss: 0.9361 - val_accuracy: 0.8438\n",
      "Epoch 15/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.7595 - accuracy: 0.8593\n",
      "Epoch 15: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 17s 34ms/step - loss: 0.7595 - accuracy: 0.8593 - val_loss: 0.9158 - val_accuracy: 0.8463\n",
      "Epoch 16/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.7256 - accuracy: 0.8636\n",
      "Epoch 16: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 18s 36ms/step - loss: 0.7256 - accuracy: 0.8636 - val_loss: 0.8981 - val_accuracy: 0.8490\n",
      "Epoch 17/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.6938 - accuracy: 0.8676\n",
      "Epoch 17: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 18s 36ms/step - loss: 0.6938 - accuracy: 0.8676 - val_loss: 0.8823 - val_accuracy: 0.8510\n",
      "Epoch 18/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.6643 - accuracy: 0.8715\n",
      "Epoch 18: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 18s 36ms/step - loss: 0.6643 - accuracy: 0.8715 - val_loss: 0.8697 - val_accuracy: 0.8521\n",
      "Epoch 19/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.6361 - accuracy: 0.8753\n",
      "Epoch 19: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 18s 36ms/step - loss: 0.6361 - accuracy: 0.8753 - val_loss: 0.8571 - val_accuracy: 0.8546\n",
      "Epoch 20/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.6097 - accuracy: 0.8790\n",
      "Epoch 20: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 18s 36ms/step - loss: 0.6097 - accuracy: 0.8790 - val_loss: 0.8449 - val_accuracy: 0.8557\n",
      "Epoch 21/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.5849 - accuracy: 0.8824\n",
      "Epoch 21: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 18s 36ms/step - loss: 0.5849 - accuracy: 0.8824 - val_loss: 0.8333 - val_accuracy: 0.8589\n",
      "Epoch 22/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.5616 - accuracy: 0.8860\n",
      "Epoch 22: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 18s 36ms/step - loss: 0.5616 - accuracy: 0.8860 - val_loss: 0.8251 - val_accuracy: 0.8604\n",
      "Epoch 23/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.5400 - accuracy: 0.8890\n",
      "Epoch 23: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 18s 36ms/step - loss: 0.5400 - accuracy: 0.8890 - val_loss: 0.8178 - val_accuracy: 0.8611\n",
      "Epoch 24/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.5197 - accuracy: 0.8920\n",
      "Epoch 24: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 18s 36ms/step - loss: 0.5197 - accuracy: 0.8920 - val_loss: 0.8100 - val_accuracy: 0.8631\n",
      "Epoch 25/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.5006 - accuracy: 0.8949\n",
      "Epoch 25: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 18s 36ms/step - loss: 0.5006 - accuracy: 0.8949 - val_loss: 0.8053 - val_accuracy: 0.8637\n",
      "Epoch 26/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.4825 - accuracy: 0.8978\n",
      "Epoch 26: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 18s 36ms/step - loss: 0.4825 - accuracy: 0.8978 - val_loss: 0.7992 - val_accuracy: 0.8649\n",
      "Epoch 27/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.4657 - accuracy: 0.9008\n",
      "Epoch 27: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 18s 36ms/step - loss: 0.4657 - accuracy: 0.9008 - val_loss: 0.7956 - val_accuracy: 0.8658\n",
      "Epoch 28/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.4498 - accuracy: 0.9035\n",
      "Epoch 28: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 18s 36ms/step - loss: 0.4498 - accuracy: 0.9035 - val_loss: 0.7936 - val_accuracy: 0.8663\n",
      "Epoch 29/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.4350 - accuracy: 0.9060\n",
      "Epoch 29: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 18s 36ms/step - loss: 0.4350 - accuracy: 0.9060 - val_loss: 0.7888 - val_accuracy: 0.8676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.4207 - accuracy: 0.9090\n",
      "Epoch 30: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 18s 36ms/step - loss: 0.4207 - accuracy: 0.9090 - val_loss: 0.7876 - val_accuracy: 0.8678\n",
      "Epoch 31/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.4073 - accuracy: 0.9113\n",
      "Epoch 31: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 18s 36ms/step - loss: 0.4073 - accuracy: 0.9113 - val_loss: 0.7845 - val_accuracy: 0.8682\n",
      "Epoch 32/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.3949 - accuracy: 0.9137\n",
      "Epoch 32: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 18s 36ms/step - loss: 0.3949 - accuracy: 0.9137 - val_loss: 0.7829 - val_accuracy: 0.8685\n",
      "Epoch 33/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.3830 - accuracy: 0.9161\n",
      "Epoch 33: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 18s 36ms/step - loss: 0.3830 - accuracy: 0.9161 - val_loss: 0.7828 - val_accuracy: 0.8691\n",
      "Epoch 34/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.3718 - accuracy: 0.9180\n",
      "Epoch 34: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 18s 36ms/step - loss: 0.3718 - accuracy: 0.9180 - val_loss: 0.7808 - val_accuracy: 0.8697\n",
      "Epoch 35/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.3612 - accuracy: 0.9203\n",
      "Epoch 35: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 18s 36ms/step - loss: 0.3612 - accuracy: 0.9203 - val_loss: 0.7805 - val_accuracy: 0.8703\n",
      "Epoch 36/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.3511 - accuracy: 0.9223\n",
      "Epoch 36: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 18s 36ms/step - loss: 0.3511 - accuracy: 0.9223 - val_loss: 0.7807 - val_accuracy: 0.8700\n",
      "Epoch 37/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.3417 - accuracy: 0.9241\n",
      "Epoch 37: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 18s 36ms/step - loss: 0.3417 - accuracy: 0.9241 - val_loss: 0.7800 - val_accuracy: 0.8707\n",
      "Epoch 38/100\n",
      "492/493 [============================>.] - ETA: 0s - loss: 0.3329 - accuracy: 0.9260\n",
      "Epoch 38: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 18s 36ms/step - loss: 0.3329 - accuracy: 0.9260 - val_loss: 0.7808 - val_accuracy: 0.8710\n",
      "Epoch 39/100\n",
      "493/493 [==============================] - ETA: 0s - loss: 0.3244 - accuracy: 0.9276\n",
      "Epoch 39: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 18s 36ms/step - loss: 0.3244 - accuracy: 0.9276 - val_loss: 0.7812 - val_accuracy: 0.8712\n",
      "Epoch 40/100\n",
      "492/493 [============================>.] - ETA: 0s - loss: 0.3165 - accuracy: 0.9290\n",
      "Epoch 40: saving model to Models\\best_Seq2seq_model.h5\n",
      "493/493 [==============================] - 18s 36ms/step - loss: 0.3165 - accuracy: 0.9290 - val_loss: 0.7824 - val_accuracy: 0.8713\n",
      "Epoch 40: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x774e7f70>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model training\n",
    "es = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=3)\n",
    "mc = ModelCheckpoint(\"Models/best_Seq2seq_model.h5\", monitor=\"val_accuracy\", mode=\"max\", verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), batch_size=128, epochs=100, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder\n",
    "encoder_model = Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoder\n",
    "decoder_state_input_h = Input(shape=(hidden_units,))\n",
    "decoder_state_input_c = Input(shape=(hidden_units,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs) #Shared layer\n",
    "\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initila_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasTensor' object has no attribute 'weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-d5e07f6c411c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec_emb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec_emb2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KerasTensor' object has no attribute 'weights'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
