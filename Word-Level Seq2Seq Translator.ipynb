{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 70000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def preprocess_sentence(sent) :\n",
    "    sent = to_ascii(sent.lower())\n",
    "    sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
    "    sent = re.sub(r\"[^a-zA-Z!.?,]+\", r\" \", sent)\n",
    "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
    "    \n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aab , ?d test .'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_sentence(\"Aab,?d ㄷ   test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocessed_data() :\n",
    "    encoder_input, decoder_input, decoder_target = [], [], []\n",
    "    \n",
    "    with open(\"DataSet/spa.txt\",\"r\") as lines :\n",
    "        for i, line in enumerate(lines) :\n",
    "            src_line, tar_line, _ = line.strip().split('\\t')\n",
    "            src_line = [w for w in preprocess_sentence(src_line).split()]\n",
    "            \n",
    "            tar_line = preprocess_sentence(tar_line)\n",
    "            tar_line_in = [w for w in (\"<sos> \" + tar_line).split()]\n",
    "            tar_line_out = [w for w in (tar_line + \" <eos>\").split()]\n",
    "            \n",
    "            encoder_input.append(src_line)\n",
    "            decoder_input.append(tar_line_in)\n",
    "            decoder_target.append(tar_line_out)\n",
    "            \n",
    "            if i==num_samples-1 :\n",
    "                break\n",
    "                \n",
    "    return encoder_input, decoder_input, decoder_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_en_in, sents_spa_in, sents_spa_out = load_preprocessed_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['go', '.'], ['go', '.'], ['go', '.'], ['go', '.'], ['hi', '.'], ['hi', '.'], ['run', '!']]\n",
      "[['<sos>', 've', '.'], ['<sos>', 'vete', '.'], ['<sos>', 'vaya', '.'], ['<sos>', 'vayase', '.'], ['<sos>', 'hola', '.'], ['<sos>', 'hola'], ['<sos>', 'corre', '!']]\n",
      "[['ve', '.', '<eos>'], ['vete', '.', '<eos>'], ['vaya', '.', '<eos>'], ['vayase', '.', '<eos>'], ['hola', '.', '<eos>'], ['hola', '<eos>'], ['corre', '!', '<eos>']]\n"
     ]
    }
   ],
   "source": [
    "print(sents_en_in[:7])\n",
    "print(sents_spa_in[:7])\n",
    "print(sents_spa_out[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = Tokenizer(filters=\"\", lower=False)\n",
    "tokenizer_en.fit_on_texts(sents_en_in)\n",
    "encoder_input = tokenizer_en.texts_to_sequences(sents_en_in)\n",
    "encoder_input = pad_sequences(encoder_input, padding=\"post\")\n",
    "\n",
    "tokenizer_spa = Tokenizer(filters=\"\", lower=False)\n",
    "tokenizer_spa.fit_on_texts(sents_spa_in)\n",
    "tokenizer_spa.fit_on_texts(sents_spa_out)\n",
    "\n",
    "decoder_input = tokenizer_spa.texts_to_sequences(sents_spa_in)\n",
    "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
    "decoder_target = tokenizer_spa.texts_to_sequences(sents_spa_out)\n",
    "decoder_target = pad_sequences(decoder_target, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 11)\n",
      "(70000, 18)\n",
      "(70000, 18)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input.shape)\n",
    "print(decoder_input.shape)\n",
    "print(decoder_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of english voca set: 8110\n",
      "Size of spanish voca set: 15842\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(tokenizer_en.word_index)+1\n",
    "tar_vocab_size = len(tokenizer_spa.word_index)+1\n",
    "print(\"Size of english voca set:\",src_vocab_size)\n",
    "print(\"Size of spanish voca set:\",tar_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_to_index = tokenizer_en.word_index\n",
    "index_to_src = tokenizer_en.index_word\n",
    "tar_to_index = tokenizer_spa.word_index\n",
    "index_to_tar = tokenizer_spa.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random sequence : [69432 25048 21868 ... 57805 11209 12168]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(\"random sequence :\",indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 19 149   8 662   9 925   1   0   0   0   0]\n",
      "[  2  21  55  15 287  11  12 948   1   0   0   0   0   0   0   0   0   0]\n",
      "[ 21  55  15 287  11  12 948   1   3   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input[0])\n",
    "print(decoder_input[0])\n",
    "print(decoder_target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test data :  7000\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(num_samples*0.1)\n",
    "print(\"Number of test data : \",n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63000, 11)\n",
      "(7000, 11)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_train.shape)\n",
    "print(encoder_input_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 512\n",
    "hidden_units = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb = Embedding(src_vocab_size, embedding_dim)(encoder_inputs)\n",
    "enc_masking = Masking(mask_value=0)(enc_emb)\n",
    "encoder_lstm = LSTM(hidden_units, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoder\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(tar_vocab_size, hidden_units)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "dec_masking = Masking(mask_value=0)(dec_emb)\n",
    "\n",
    "decoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_masking, initial_state=encoder_states)\n",
    "\n",
    "decoder_dense = Dense(tar_vocab_size, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model compile\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "493/493 [==============================] - 43s 64ms/step - loss: 1.8081 - accuracy: 0.7431 - val_loss: 1.4656 - val_accuracy: 0.7746\n",
      "Epoch 2/600\n",
      "493/493 [==============================] - 28s 56ms/step - loss: 1.3305 - accuracy: 0.7909 - val_loss: 1.2418 - val_accuracy: 0.8064\n",
      "Epoch 3/600\n",
      "493/493 [==============================] - 28s 56ms/step - loss: 1.1028 - accuracy: 0.8176 - val_loss: 1.0759 - val_accuracy: 0.8251\n",
      "Epoch 4/600\n",
      "493/493 [==============================] - 28s 56ms/step - loss: 0.9223 - accuracy: 0.8387 - val_loss: 0.9542 - val_accuracy: 0.8427\n",
      "Epoch 5/600\n",
      "493/493 [==============================] - 27s 55ms/step - loss: 0.7753 - accuracy: 0.8570 - val_loss: 0.8594 - val_accuracy: 0.8559\n",
      "Epoch 6/600\n",
      "493/493 [==============================] - 27s 55ms/step - loss: 0.6493 - accuracy: 0.8738 - val_loss: 0.7863 - val_accuracy: 0.8677\n",
      "Epoch 7/600\n",
      "493/493 [==============================] - 27s 55ms/step - loss: 0.5389 - accuracy: 0.8899 - val_loss: 0.7286 - val_accuracy: 0.8777\n",
      "Epoch 8/600\n",
      "493/493 [==============================] - 27s 55ms/step - loss: 0.4432 - accuracy: 0.9050 - val_loss: 0.6858 - val_accuracy: 0.8850\n",
      "Epoch 9/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.3624 - accuracy: 0.9189 - val_loss: 0.6587 - val_accuracy: 0.8895\n",
      "Epoch 10/600\n",
      "493/493 [==============================] - 28s 57ms/step - loss: 0.2961 - accuracy: 0.9317 - val_loss: 0.6409 - val_accuracy: 0.8937\n",
      "Epoch 11/600\n",
      "493/493 [==============================] - 27s 55ms/step - loss: 0.2430 - accuracy: 0.9427 - val_loss: 0.6279 - val_accuracy: 0.8962\n",
      "Epoch 12/600\n",
      "493/493 [==============================] - 28s 56ms/step - loss: 0.2009 - accuracy: 0.9518 - val_loss: 0.6272 - val_accuracy: 0.8968\n",
      "Epoch 13/600\n",
      "493/493 [==============================] - 28s 56ms/step - loss: 0.1684 - accuracy: 0.9587 - val_loss: 0.6283 - val_accuracy: 0.8983\n",
      "Epoch 14/600\n",
      "493/493 [==============================] - 28s 56ms/step - loss: 0.1429 - accuracy: 0.9642 - val_loss: 0.6352 - val_accuracy: 0.8984\n",
      "Epoch 15/600\n",
      "493/493 [==============================] - 28s 56ms/step - loss: 0.1231 - accuracy: 0.9685 - val_loss: 0.6381 - val_accuracy: 0.8991\n",
      "Epoch 16/600\n",
      "493/493 [==============================] - 28s 57ms/step - loss: 0.1068 - accuracy: 0.9721 - val_loss: 0.6449 - val_accuracy: 0.8991\n",
      "Epoch 17/600\n",
      "493/493 [==============================] - 28s 56ms/step - loss: 0.0942 - accuracy: 0.9748 - val_loss: 0.6564 - val_accuracy: 0.8991\n",
      "Epoch 18/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0844 - accuracy: 0.9769 - val_loss: 0.6677 - val_accuracy: 0.8978\n",
      "Epoch 19/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0763 - accuracy: 0.9788 - val_loss: 0.6761 - val_accuracy: 0.8987\n",
      "Epoch 20/600\n",
      "493/493 [==============================] - 27s 55ms/step - loss: 0.0697 - accuracy: 0.9802 - val_loss: 0.6858 - val_accuracy: 0.8987\n",
      "Epoch 21/600\n",
      "493/493 [==============================] - 27s 56ms/step - loss: 0.0644 - accuracy: 0.9814 - val_loss: 0.6940 - val_accuracy: 0.8980\n",
      "Epoch 22/600\n",
      "493/493 [==============================] - 28s 56ms/step - loss: 0.0608 - accuracy: 0.9821 - val_loss: 0.6998 - val_accuracy: 0.8988\n",
      "Epoch 23/600\n",
      "493/493 [==============================] - 27s 56ms/step - loss: 0.0572 - accuracy: 0.9828 - val_loss: 0.7097 - val_accuracy: 0.8980\n",
      "Epoch 24/600\n",
      "493/493 [==============================] - 27s 56ms/step - loss: 0.0551 - accuracy: 0.9833 - val_loss: 0.7192 - val_accuracy: 0.8990\n",
      "Epoch 25/600\n",
      "493/493 [==============================] - 27s 55ms/step - loss: 0.0526 - accuracy: 0.9838 - val_loss: 0.7221 - val_accuracy: 0.8992\n",
      "Epoch 26/600\n",
      "493/493 [==============================] - 28s 56ms/step - loss: 0.0503 - accuracy: 0.9843 - val_loss: 0.7316 - val_accuracy: 0.8988\n",
      "Epoch 27/600\n",
      "493/493 [==============================] - 28s 56ms/step - loss: 0.0495 - accuracy: 0.9844 - val_loss: 0.7355 - val_accuracy: 0.8983\n",
      "Epoch 28/600\n",
      "493/493 [==============================] - 27s 55ms/step - loss: 0.0482 - accuracy: 0.9846 - val_loss: 0.7429 - val_accuracy: 0.8986\n",
      "Epoch 29/600\n",
      "493/493 [==============================] - 27s 55ms/step - loss: 0.0468 - accuracy: 0.9847 - val_loss: 0.7491 - val_accuracy: 0.8982\n",
      "Epoch 30/600\n",
      "493/493 [==============================] - 28s 56ms/step - loss: 0.0460 - accuracy: 0.9848 - val_loss: 0.7562 - val_accuracy: 0.8991\n",
      "Epoch 31/600\n",
      "493/493 [==============================] - 27s 55ms/step - loss: 0.0455 - accuracy: 0.9850 - val_loss: 0.7527 - val_accuracy: 0.8985\n",
      "Epoch 32/600\n",
      "493/493 [==============================] - 28s 56ms/step - loss: 0.0447 - accuracy: 0.9851 - val_loss: 0.7643 - val_accuracy: 0.8979\n",
      "Epoch 33/600\n",
      "493/493 [==============================] - 28s 57ms/step - loss: 0.0439 - accuracy: 0.9851 - val_loss: 0.7653 - val_accuracy: 0.8981\n",
      "Epoch 34/600\n",
      "493/493 [==============================] - 28s 56ms/step - loss: 0.0433 - accuracy: 0.9852 - val_loss: 0.7676 - val_accuracy: 0.8984\n",
      "Epoch 35/600\n",
      "493/493 [==============================] - 27s 55ms/step - loss: 0.0426 - accuracy: 0.9853 - val_loss: 0.7689 - val_accuracy: 0.8988\n",
      "Epoch 36/600\n",
      "493/493 [==============================] - 28s 56ms/step - loss: 0.0424 - accuracy: 0.9852 - val_loss: 0.7791 - val_accuracy: 0.8985\n",
      "Epoch 37/600\n",
      "493/493 [==============================] - 28s 56ms/step - loss: 0.0415 - accuracy: 0.9854 - val_loss: 0.7809 - val_accuracy: 0.8982\n",
      "Epoch 38/600\n",
      "493/493 [==============================] - 28s 57ms/step - loss: 0.0414 - accuracy: 0.9855 - val_loss: 0.7857 - val_accuracy: 0.8986\n",
      "Epoch 39/600\n",
      "493/493 [==============================] - 27s 55ms/step - loss: 0.0411 - accuracy: 0.9855 - val_loss: 0.7897 - val_accuracy: 0.8982\n",
      "Epoch 40/600\n",
      "493/493 [==============================] - 27s 55ms/step - loss: 0.0404 - accuracy: 0.9856 - val_loss: 0.7900 - val_accuracy: 0.8979\n",
      "Epoch 41/600\n",
      "493/493 [==============================] - 28s 56ms/step - loss: 0.0402 - accuracy: 0.9855 - val_loss: 0.7923 - val_accuracy: 0.8981\n",
      "Epoch 42/600\n",
      "493/493 [==============================] - 27s 55ms/step - loss: 0.0400 - accuracy: 0.9855 - val_loss: 0.7965 - val_accuracy: 0.8986\n",
      "Epoch 43/600\n",
      "493/493 [==============================] - 27s 55ms/step - loss: 0.0396 - accuracy: 0.9856 - val_loss: 0.7952 - val_accuracy: 0.8986\n",
      "Epoch 44/600\n",
      "493/493 [==============================] - 28s 56ms/step - loss: 0.0393 - accuracy: 0.9856 - val_loss: 0.8006 - val_accuracy: 0.8984\n",
      "Epoch 45/600\n",
      "493/493 [==============================] - 28s 56ms/step - loss: 0.0388 - accuracy: 0.9857 - val_loss: 0.8036 - val_accuracy: 0.8982\n",
      "Epoch 46/600\n",
      "493/493 [==============================] - 29s 58ms/step - loss: 0.0385 - accuracy: 0.9857 - val_loss: 0.8087 - val_accuracy: 0.8985\n",
      "Epoch 47/600\n",
      "493/493 [==============================] - 29s 58ms/step - loss: 0.0385 - accuracy: 0.9857 - val_loss: 0.8056 - val_accuracy: 0.8984\n",
      "Epoch 48/600\n",
      "493/493 [==============================] - 30s 61ms/step - loss: 0.0381 - accuracy: 0.9857 - val_loss: 0.8042 - val_accuracy: 0.8986\n",
      "Epoch 49/600\n",
      "493/493 [==============================] - 28s 58ms/step - loss: 0.0377 - accuracy: 0.9858 - val_loss: 0.8154 - val_accuracy: 0.8979\n",
      "Epoch 50/600\n",
      "493/493 [==============================] - 28s 58ms/step - loss: 0.0374 - accuracy: 0.9858 - val_loss: 0.8089 - val_accuracy: 0.8983\n",
      "Epoch 51/600\n",
      "493/493 [==============================] - 29s 59ms/step - loss: 0.0375 - accuracy: 0.9858 - val_loss: 0.8134 - val_accuracy: 0.8984\n",
      "Epoch 52/600\n",
      "493/493 [==============================] - 30s 60ms/step - loss: 0.0372 - accuracy: 0.9858 - val_loss: 0.8151 - val_accuracy: 0.8984\n",
      "Epoch 53/600\n",
      "493/493 [==============================] - 29s 59ms/step - loss: 0.0368 - accuracy: 0.9858 - val_loss: 0.8170 - val_accuracy: 0.8988\n",
      "Epoch 54/600\n",
      "493/493 [==============================] - 28s 57ms/step - loss: 0.0367 - accuracy: 0.9858 - val_loss: 0.8210 - val_accuracy: 0.8987\n",
      "Epoch 55/600\n",
      "493/493 [==============================] - 28s 57ms/step - loss: 0.0363 - accuracy: 0.9858 - val_loss: 0.8238 - val_accuracy: 0.8980\n",
      "Epoch 56/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0362 - accuracy: 0.9858 - val_loss: 0.8246 - val_accuracy: 0.8979\n",
      "Epoch 57/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493/493 [==============================] - 30s 60ms/step - loss: 0.0357 - accuracy: 0.9859 - val_loss: 0.8331 - val_accuracy: 0.8978\n",
      "Epoch 58/600\n",
      "493/493 [==============================] - 28s 57ms/step - loss: 0.0360 - accuracy: 0.9858 - val_loss: 0.8220 - val_accuracy: 0.8983\n",
      "Epoch 59/600\n",
      "493/493 [==============================] - 29s 58ms/step - loss: 0.0359 - accuracy: 0.9858 - val_loss: 0.8261 - val_accuracy: 0.8979\n",
      "Epoch 60/600\n",
      "493/493 [==============================] - 28s 57ms/step - loss: 0.0356 - accuracy: 0.9858 - val_loss: 0.8324 - val_accuracy: 0.8977\n",
      "Epoch 61/600\n",
      "493/493 [==============================] - 28s 57ms/step - loss: 0.0353 - accuracy: 0.9859 - val_loss: 0.8305 - val_accuracy: 0.8977\n",
      "Epoch 62/600\n",
      "493/493 [==============================] - 28s 57ms/step - loss: 0.0351 - accuracy: 0.9859 - val_loss: 0.8266 - val_accuracy: 0.8981\n",
      "Epoch 63/600\n",
      "493/493 [==============================] - 28s 56ms/step - loss: 0.0349 - accuracy: 0.9859 - val_loss: 0.8368 - val_accuracy: 0.8979\n",
      "Epoch 64/600\n",
      "493/493 [==============================] - 28s 58ms/step - loss: 0.0348 - accuracy: 0.9859 - val_loss: 0.8326 - val_accuracy: 0.8970\n",
      "Epoch 65/600\n",
      "493/493 [==============================] - 29s 59ms/step - loss: 0.0347 - accuracy: 0.9859 - val_loss: 0.8342 - val_accuracy: 0.8978\n",
      "Epoch 66/600\n",
      "493/493 [==============================] - 29s 60ms/step - loss: 0.0345 - accuracy: 0.9859 - val_loss: 0.8337 - val_accuracy: 0.8980\n",
      "Epoch 67/600\n",
      "493/493 [==============================] - 28s 57ms/step - loss: 0.0346 - accuracy: 0.9859 - val_loss: 0.8363 - val_accuracy: 0.8984\n",
      "Epoch 68/600\n",
      "493/493 [==============================] - 28s 57ms/step - loss: 0.0342 - accuracy: 0.9859 - val_loss: 0.8387 - val_accuracy: 0.8978\n",
      "Epoch 69/600\n",
      "493/493 [==============================] - 28s 56ms/step - loss: 0.0342 - accuracy: 0.9859 - val_loss: 0.8374 - val_accuracy: 0.8977\n",
      "Epoch 70/600\n",
      "493/493 [==============================] - 28s 56ms/step - loss: 0.0340 - accuracy: 0.9859 - val_loss: 0.8441 - val_accuracy: 0.8980\n",
      "Epoch 71/600\n",
      "493/493 [==============================] - 29s 59ms/step - loss: 0.0337 - accuracy: 0.9859 - val_loss: 0.8367 - val_accuracy: 0.8981\n",
      "Epoch 72/600\n",
      "493/493 [==============================] - 29s 59ms/step - loss: 0.0336 - accuracy: 0.9859 - val_loss: 0.8431 - val_accuracy: 0.8977\n",
      "Epoch 73/600\n",
      "493/493 [==============================] - 29s 59ms/step - loss: 0.0336 - accuracy: 0.9858 - val_loss: 0.8445 - val_accuracy: 0.8973\n",
      "Epoch 74/600\n",
      "493/493 [==============================] - 29s 59ms/step - loss: 0.0332 - accuracy: 0.9859 - val_loss: 0.8470 - val_accuracy: 0.8976\n",
      "Epoch 75/600\n",
      "493/493 [==============================] - 29s 59ms/step - loss: 0.0333 - accuracy: 0.9859 - val_loss: 0.8497 - val_accuracy: 0.8977\n",
      "Epoch 76/600\n",
      "493/493 [==============================] - 29s 59ms/step - loss: 0.0331 - accuracy: 0.9859 - val_loss: 0.8473 - val_accuracy: 0.8980\n",
      "Epoch 77/600\n",
      "493/493 [==============================] - 30s 60ms/step - loss: 0.0331 - accuracy: 0.9859 - val_loss: 0.8472 - val_accuracy: 0.8977\n",
      "Epoch 78/600\n",
      "493/493 [==============================] - 29s 59ms/step - loss: 0.0329 - accuracy: 0.9860 - val_loss: 0.8478 - val_accuracy: 0.8976\n",
      "Epoch 79/600\n",
      "493/493 [==============================] - 29s 59ms/step - loss: 0.0330 - accuracy: 0.9859 - val_loss: 0.8508 - val_accuracy: 0.8975\n",
      "Epoch 80/600\n",
      "493/493 [==============================] - 29s 59ms/step - loss: 0.0324 - accuracy: 0.9860 - val_loss: 0.8587 - val_accuracy: 0.8975\n",
      "Epoch 81/600\n",
      "493/493 [==============================] - 30s 61ms/step - loss: 0.0325 - accuracy: 0.9859 - val_loss: 0.8553 - val_accuracy: 0.8974\n",
      "Epoch 82/600\n",
      "493/493 [==============================] - 30s 61ms/step - loss: 0.0324 - accuracy: 0.9860 - val_loss: 0.8523 - val_accuracy: 0.8976\n",
      "Epoch 83/600\n",
      "493/493 [==============================] - 29s 59ms/step - loss: 0.0325 - accuracy: 0.9859 - val_loss: 0.8602 - val_accuracy: 0.8971\n",
      "Epoch 84/600\n",
      "493/493 [==============================] - 29s 59ms/step - loss: 0.0322 - accuracy: 0.9860 - val_loss: 0.8584 - val_accuracy: 0.8980\n",
      "Epoch 85/600\n",
      "493/493 [==============================] - 29s 60ms/step - loss: 0.0317 - accuracy: 0.9860 - val_loss: 0.8560 - val_accuracy: 0.8979\n",
      "Epoch 86/600\n",
      "493/493 [==============================] - 29s 59ms/step - loss: 0.0319 - accuracy: 0.9860 - val_loss: 0.8596 - val_accuracy: 0.8974\n",
      "Epoch 87/600\n",
      "493/493 [==============================] - 30s 60ms/step - loss: 0.0318 - accuracy: 0.9860 - val_loss: 0.8595 - val_accuracy: 0.8979\n",
      "Epoch 88/600\n",
      "493/493 [==============================] - 29s 60ms/step - loss: 0.0319 - accuracy: 0.9859 - val_loss: 0.8595 - val_accuracy: 0.8977\n",
      "Epoch 89/600\n",
      "493/493 [==============================] - 29s 58ms/step - loss: 0.0317 - accuracy: 0.9860 - val_loss: 0.8688 - val_accuracy: 0.8977\n",
      "Epoch 90/600\n",
      "493/493 [==============================] - 28s 57ms/step - loss: 0.0318 - accuracy: 0.9859 - val_loss: 0.8616 - val_accuracy: 0.8978\n",
      "Epoch 91/600\n",
      "493/493 [==============================] - 28s 57ms/step - loss: 0.0316 - accuracy: 0.9860 - val_loss: 0.8652 - val_accuracy: 0.8976\n",
      "Epoch 92/600\n",
      "493/493 [==============================] - 30s 60ms/step - loss: 0.0313 - accuracy: 0.9859 - val_loss: 0.8646 - val_accuracy: 0.8978\n",
      "Epoch 93/600\n",
      "493/493 [==============================] - 31s 62ms/step - loss: 0.0311 - accuracy: 0.9860 - val_loss: 0.8626 - val_accuracy: 0.8980\n",
      "Epoch 94/600\n",
      "493/493 [==============================] - 30s 61ms/step - loss: 0.0312 - accuracy: 0.9860 - val_loss: 0.8678 - val_accuracy: 0.8979\n",
      "Epoch 95/600\n",
      "493/493 [==============================] - 30s 61ms/step - loss: 0.0311 - accuracy: 0.9860 - val_loss: 0.8698 - val_accuracy: 0.8971\n",
      "Epoch 96/600\n",
      "493/493 [==============================] - 30s 61ms/step - loss: 0.0310 - accuracy: 0.9860 - val_loss: 0.8687 - val_accuracy: 0.8976\n",
      "Epoch 97/600\n",
      "493/493 [==============================] - 31s 63ms/step - loss: 0.0310 - accuracy: 0.9859 - val_loss: 0.8707 - val_accuracy: 0.8970\n",
      "Epoch 98/600\n",
      "493/493 [==============================] - 30s 62ms/step - loss: 0.0308 - accuracy: 0.9860 - val_loss: 0.8729 - val_accuracy: 0.8970\n",
      "Epoch 99/600\n",
      "493/493 [==============================] - 29s 59ms/step - loss: 0.0305 - accuracy: 0.9861 - val_loss: 0.8790 - val_accuracy: 0.8966\n",
      "Epoch 100/600\n",
      "493/493 [==============================] - 27s 55ms/step - loss: 0.0304 - accuracy: 0.9861 - val_loss: 0.8710 - val_accuracy: 0.8972\n",
      "Epoch 101/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0306 - accuracy: 0.9859 - val_loss: 0.8770 - val_accuracy: 0.8970\n",
      "Epoch 102/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0305 - accuracy: 0.9861 - val_loss: 0.8755 - val_accuracy: 0.8966\n",
      "Epoch 103/600\n",
      "493/493 [==============================] - 27s 55ms/step - loss: 0.0304 - accuracy: 0.9860 - val_loss: 0.8787 - val_accuracy: 0.8968\n",
      "Epoch 104/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0304 - accuracy: 0.9860 - val_loss: 0.8780 - val_accuracy: 0.8972\n",
      "Epoch 105/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0303 - accuracy: 0.9860 - val_loss: 0.8790 - val_accuracy: 0.8969\n",
      "Epoch 106/600\n",
      "493/493 [==============================] - 27s 55ms/step - loss: 0.0302 - accuracy: 0.9860 - val_loss: 0.8842 - val_accuracy: 0.8965\n",
      "Epoch 107/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0301 - accuracy: 0.9860 - val_loss: 0.8825 - val_accuracy: 0.8972\n",
      "Epoch 108/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0299 - accuracy: 0.9860 - val_loss: 0.8845 - val_accuracy: 0.8969\n",
      "Epoch 109/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0300 - accuracy: 0.9860 - val_loss: 0.8855 - val_accuracy: 0.8972\n",
      "Epoch 110/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0299 - accuracy: 0.9860 - val_loss: 0.8886 - val_accuracy: 0.8971\n",
      "Epoch 111/600\n",
      "493/493 [==============================] - 27s 55ms/step - loss: 0.0298 - accuracy: 0.9860 - val_loss: 0.8869 - val_accuracy: 0.8967\n",
      "Epoch 112/600\n",
      "493/493 [==============================] - 27s 55ms/step - loss: 0.0296 - accuracy: 0.9860 - val_loss: 0.8830 - val_accuracy: 0.8962\n",
      "Epoch 113/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0295 - accuracy: 0.9860 - val_loss: 0.8880 - val_accuracy: 0.8969\n",
      "Epoch 114/600\n",
      "493/493 [==============================] - 27s 55ms/step - loss: 0.0296 - accuracy: 0.9860 - val_loss: 0.8825 - val_accuracy: 0.8967\n",
      "Epoch 115/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0294 - accuracy: 0.9861 - val_loss: 0.8895 - val_accuracy: 0.8967\n",
      "Epoch 116/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0294 - accuracy: 0.9860 - val_loss: 0.8896 - val_accuracy: 0.8971\n",
      "Epoch 117/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0292 - accuracy: 0.9860 - val_loss: 0.8933 - val_accuracy: 0.8967\n",
      "Epoch 118/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0292 - accuracy: 0.9861 - val_loss: 0.8887 - val_accuracy: 0.8962\n",
      "Epoch 119/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0293 - accuracy: 0.9860 - val_loss: 0.9004 - val_accuracy: 0.8963\n",
      "Epoch 120/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0294 - accuracy: 0.9860 - val_loss: 0.8971 - val_accuracy: 0.8964\n",
      "Epoch 121/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0292 - accuracy: 0.9860 - val_loss: 0.8939 - val_accuracy: 0.8963\n",
      "Epoch 122/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0291 - accuracy: 0.9860 - val_loss: 0.8962 - val_accuracy: 0.8962\n",
      "Epoch 123/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0288 - accuracy: 0.9861 - val_loss: 0.8982 - val_accuracy: 0.8968\n",
      "Epoch 124/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0288 - accuracy: 0.9860 - val_loss: 0.9029 - val_accuracy: 0.8959\n",
      "Epoch 125/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0287 - accuracy: 0.9860 - val_loss: 0.8970 - val_accuracy: 0.8965\n",
      "Epoch 126/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0289 - accuracy: 0.9859 - val_loss: 0.9024 - val_accuracy: 0.8966\n",
      "Epoch 127/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0289 - accuracy: 0.9860 - val_loss: 0.9028 - val_accuracy: 0.8957\n",
      "Epoch 128/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0290 - accuracy: 0.9859 - val_loss: 0.9048 - val_accuracy: 0.8962\n",
      "Epoch 129/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0289 - accuracy: 0.9861 - val_loss: 0.9031 - val_accuracy: 0.8965\n",
      "Epoch 130/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0288 - accuracy: 0.9860 - val_loss: 0.9024 - val_accuracy: 0.8958\n",
      "Epoch 131/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0284 - accuracy: 0.9860 - val_loss: 0.9025 - val_accuracy: 0.8961\n",
      "Epoch 132/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0282 - accuracy: 0.9860 - val_loss: 0.9094 - val_accuracy: 0.8965\n",
      "Epoch 133/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0280 - accuracy: 0.9861 - val_loss: 0.9074 - val_accuracy: 0.8960\n",
      "Epoch 134/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0280 - accuracy: 0.9861 - val_loss: 0.9094 - val_accuracy: 0.8963\n",
      "Epoch 135/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0281 - accuracy: 0.9860 - val_loss: 0.9062 - val_accuracy: 0.8965\n",
      "Epoch 136/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0282 - accuracy: 0.9861 - val_loss: 0.9144 - val_accuracy: 0.8964\n",
      "Epoch 137/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0284 - accuracy: 0.9860 - val_loss: 0.9171 - val_accuracy: 0.8963\n",
      "Epoch 138/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0283 - accuracy: 0.9860 - val_loss: 0.9129 - val_accuracy: 0.8960\n",
      "Epoch 139/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0284 - accuracy: 0.9859 - val_loss: 0.9084 - val_accuracy: 0.8958\n",
      "Epoch 140/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0282 - accuracy: 0.9861 - val_loss: 0.9148 - val_accuracy: 0.8960\n",
      "Epoch 141/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0281 - accuracy: 0.9861 - val_loss: 0.9141 - val_accuracy: 0.8963\n",
      "Epoch 142/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0278 - accuracy: 0.9860 - val_loss: 0.9188 - val_accuracy: 0.8962\n",
      "Epoch 143/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0277 - accuracy: 0.9860 - val_loss: 0.9230 - val_accuracy: 0.8961\n",
      "Epoch 144/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0277 - accuracy: 0.9860 - val_loss: 0.9204 - val_accuracy: 0.8957\n",
      "Epoch 145/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0275 - accuracy: 0.9860 - val_loss: 0.9186 - val_accuracy: 0.8957\n",
      "Epoch 146/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0277 - accuracy: 0.9860 - val_loss: 0.9222 - val_accuracy: 0.8962\n",
      "Epoch 147/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0276 - accuracy: 0.9861 - val_loss: 0.9249 - val_accuracy: 0.8963\n",
      "Epoch 148/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0277 - accuracy: 0.9859 - val_loss: 0.9217 - val_accuracy: 0.8958\n",
      "Epoch 149/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0279 - accuracy: 0.9860 - val_loss: 0.9240 - val_accuracy: 0.8955\n",
      "Epoch 150/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0279 - accuracy: 0.9860 - val_loss: 0.9280 - val_accuracy: 0.8960\n",
      "Epoch 151/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0278 - accuracy: 0.9859 - val_loss: 0.9258 - val_accuracy: 0.8956\n",
      "Epoch 152/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0275 - accuracy: 0.9859 - val_loss: 0.9290 - val_accuracy: 0.8967\n",
      "Epoch 153/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0272 - accuracy: 0.9861 - val_loss: 0.9297 - val_accuracy: 0.8954\n",
      "Epoch 154/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0271 - accuracy: 0.9861 - val_loss: 0.9318 - val_accuracy: 0.8957\n",
      "Epoch 155/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0271 - accuracy: 0.9861 - val_loss: 0.9274 - val_accuracy: 0.8961\n",
      "Epoch 156/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0271 - accuracy: 0.9861 - val_loss: 0.9206 - val_accuracy: 0.8955\n",
      "Epoch 157/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0271 - accuracy: 0.9860 - val_loss: 0.9328 - val_accuracy: 0.8950\n",
      "Epoch 158/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0272 - accuracy: 0.9860 - val_loss: 0.9409 - val_accuracy: 0.8956\n",
      "Epoch 159/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0273 - accuracy: 0.9860 - val_loss: 0.9287 - val_accuracy: 0.8946\n",
      "Epoch 160/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0274 - accuracy: 0.9859 - val_loss: 0.9506 - val_accuracy: 0.8952\n",
      "Epoch 161/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0275 - accuracy: 0.9860 - val_loss: 0.9332 - val_accuracy: 0.8957\n",
      "Epoch 162/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0272 - accuracy: 0.9860 - val_loss: 0.9359 - val_accuracy: 0.8954\n",
      "Epoch 163/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0271 - accuracy: 0.9860 - val_loss: 0.9432 - val_accuracy: 0.8952\n",
      "Epoch 164/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0269 - accuracy: 0.9861 - val_loss: 0.9362 - val_accuracy: 0.8953\n",
      "Epoch 165/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0268 - accuracy: 0.9860 - val_loss: 0.9366 - val_accuracy: 0.8957\n",
      "Epoch 166/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0267 - accuracy: 0.9860 - val_loss: 0.9435 - val_accuracy: 0.8956\n",
      "Epoch 167/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0267 - accuracy: 0.9861 - val_loss: 0.9443 - val_accuracy: 0.8955\n",
      "Epoch 168/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0267 - accuracy: 0.9860 - val_loss: 0.9418 - val_accuracy: 0.8953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0267 - accuracy: 0.9860 - val_loss: 0.9308 - val_accuracy: 0.8954\n",
      "Epoch 170/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0268 - accuracy: 0.9861 - val_loss: 0.9443 - val_accuracy: 0.8953\n",
      "Epoch 171/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0272 - accuracy: 0.9860 - val_loss: 0.9428 - val_accuracy: 0.8955\n",
      "Epoch 172/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0272 - accuracy: 0.9859 - val_loss: 0.9428 - val_accuracy: 0.8950\n",
      "Epoch 173/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0271 - accuracy: 0.9860 - val_loss: 0.9425 - val_accuracy: 0.8953\n",
      "Epoch 174/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0268 - accuracy: 0.9861 - val_loss: 0.9515 - val_accuracy: 0.8955\n",
      "Epoch 175/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0265 - accuracy: 0.9860 - val_loss: 0.9433 - val_accuracy: 0.8952\n",
      "Epoch 176/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0262 - accuracy: 0.9861 - val_loss: 0.9423 - val_accuracy: 0.8952\n",
      "Epoch 177/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0260 - accuracy: 0.9861 - val_loss: 0.9484 - val_accuracy: 0.8952\n",
      "Epoch 178/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0261 - accuracy: 0.9861 - val_loss: 0.9575 - val_accuracy: 0.8958\n",
      "Epoch 179/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0262 - accuracy: 0.9861 - val_loss: 0.9508 - val_accuracy: 0.8950\n",
      "Epoch 180/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0265 - accuracy: 0.9860 - val_loss: 0.9529 - val_accuracy: 0.8954\n",
      "Epoch 181/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0267 - accuracy: 0.9860 - val_loss: 0.9526 - val_accuracy: 0.8944\n",
      "Epoch 182/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0272 - accuracy: 0.9859 - val_loss: 0.9531 - val_accuracy: 0.8944\n",
      "Epoch 183/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0269 - accuracy: 0.9859 - val_loss: 0.9571 - val_accuracy: 0.8948\n",
      "Epoch 184/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0266 - accuracy: 0.9861 - val_loss: 0.9548 - val_accuracy: 0.8955\n",
      "Epoch 185/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0263 - accuracy: 0.9860 - val_loss: 0.9529 - val_accuracy: 0.8956\n",
      "Epoch 186/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0260 - accuracy: 0.9861 - val_loss: 0.9575 - val_accuracy: 0.8950\n",
      "Epoch 187/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0257 - accuracy: 0.9861 - val_loss: 0.9578 - val_accuracy: 0.8951\n",
      "Epoch 188/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0257 - accuracy: 0.9860 - val_loss: 0.9570 - val_accuracy: 0.8950\n",
      "Epoch 189/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0258 - accuracy: 0.9861 - val_loss: 0.9629 - val_accuracy: 0.8951\n",
      "Epoch 190/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0258 - accuracy: 0.9861 - val_loss: 0.9684 - val_accuracy: 0.8948\n",
      "Epoch 191/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0263 - accuracy: 0.9861 - val_loss: 0.9682 - val_accuracy: 0.8948\n",
      "Epoch 192/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0273 - accuracy: 0.9859 - val_loss: 0.9642 - val_accuracy: 0.8932\n",
      "Epoch 193/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0275 - accuracy: 0.9859 - val_loss: 0.9709 - val_accuracy: 0.8940\n",
      "Epoch 194/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0270 - accuracy: 0.9860 - val_loss: 0.9645 - val_accuracy: 0.8948\n",
      "Epoch 195/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0263 - accuracy: 0.9861 - val_loss: 0.9715 - val_accuracy: 0.8948\n",
      "Epoch 196/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0258 - accuracy: 0.9861 - val_loss: 0.9624 - val_accuracy: 0.8949\n",
      "Epoch 197/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0255 - accuracy: 0.9860 - val_loss: 0.9703 - val_accuracy: 0.8944\n",
      "Epoch 198/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0252 - accuracy: 0.9862 - val_loss: 0.9743 - val_accuracy: 0.8946\n",
      "Epoch 199/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0253 - accuracy: 0.9861 - val_loss: 0.9672 - val_accuracy: 0.8956\n",
      "Epoch 200/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0255 - accuracy: 0.9860 - val_loss: 0.9772 - val_accuracy: 0.8946\n",
      "Epoch 201/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0255 - accuracy: 0.9861 - val_loss: 0.9739 - val_accuracy: 0.8948\n",
      "Epoch 202/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0259 - accuracy: 0.9860 - val_loss: 0.9770 - val_accuracy: 0.8949\n",
      "Epoch 203/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0263 - accuracy: 0.9860 - val_loss: 0.9756 - val_accuracy: 0.8949\n",
      "Epoch 204/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0274 - accuracy: 0.9859 - val_loss: 0.9798 - val_accuracy: 0.8936\n",
      "Epoch 205/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0274 - accuracy: 0.9859 - val_loss: 0.9735 - val_accuracy: 0.8944\n",
      "Epoch 206/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0264 - accuracy: 0.9861 - val_loss: 0.9683 - val_accuracy: 0.8943\n",
      "Epoch 207/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0255 - accuracy: 0.9861 - val_loss: 0.9734 - val_accuracy: 0.8946\n",
      "Epoch 208/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0252 - accuracy: 0.9861 - val_loss: 0.9783 - val_accuracy: 0.8946\n",
      "Epoch 209/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0250 - accuracy: 0.9861 - val_loss: 0.9819 - val_accuracy: 0.8946\n",
      "Epoch 210/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0251 - accuracy: 0.9862 - val_loss: 0.9747 - val_accuracy: 0.8951\n",
      "Epoch 211/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0252 - accuracy: 0.9860 - val_loss: 0.9837 - val_accuracy: 0.8947\n",
      "Epoch 212/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0254 - accuracy: 0.9861 - val_loss: 0.9821 - val_accuracy: 0.8949\n",
      "Epoch 213/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0258 - accuracy: 0.9861 - val_loss: 0.9807 - val_accuracy: 0.8941\n",
      "Epoch 214/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0266 - accuracy: 0.9860 - val_loss: 0.9835 - val_accuracy: 0.8941\n",
      "Epoch 215/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0267 - accuracy: 0.9860 - val_loss: 0.9912 - val_accuracy: 0.8936\n",
      "Epoch 216/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0265 - accuracy: 0.9859 - val_loss: 0.9889 - val_accuracy: 0.8933\n",
      "Epoch 217/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0260 - accuracy: 0.9859 - val_loss: 0.9858 - val_accuracy: 0.8939\n",
      "Epoch 218/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0254 - accuracy: 0.9861 - val_loss: 0.9877 - val_accuracy: 0.8941\n",
      "Epoch 219/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0250 - accuracy: 0.9861 - val_loss: 0.9921 - val_accuracy: 0.8945\n",
      "Epoch 220/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0249 - accuracy: 0.9860 - val_loss: 0.9844 - val_accuracy: 0.8946\n",
      "Epoch 221/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0250 - accuracy: 0.9860 - val_loss: 0.9862 - val_accuracy: 0.8941\n",
      "Epoch 222/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0251 - accuracy: 0.9861 - val_loss: 0.9954 - val_accuracy: 0.8944\n",
      "Epoch 223/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0255 - accuracy: 0.9860 - val_loss: 0.9941 - val_accuracy: 0.8936\n",
      "Epoch 224/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0262 - accuracy: 0.9860 - val_loss: 0.9937 - val_accuracy: 0.8936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0263 - accuracy: 0.9859 - val_loss: 1.0001 - val_accuracy: 0.8938\n",
      "Epoch 226/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0261 - accuracy: 0.9860 - val_loss: 0.9910 - val_accuracy: 0.8939\n",
      "Epoch 227/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0257 - accuracy: 0.9861 - val_loss: 0.9972 - val_accuracy: 0.8942\n",
      "Epoch 228/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0252 - accuracy: 0.9860 - val_loss: 1.0038 - val_accuracy: 0.8946\n",
      "Epoch 229/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0250 - accuracy: 0.9861 - val_loss: 0.9926 - val_accuracy: 0.8942\n",
      "Epoch 230/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0249 - accuracy: 0.9861 - val_loss: 1.0036 - val_accuracy: 0.8943\n",
      "Epoch 231/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0249 - accuracy: 0.9861 - val_loss: 1.0002 - val_accuracy: 0.8940\n",
      "Epoch 232/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0249 - accuracy: 0.9861 - val_loss: 1.0033 - val_accuracy: 0.8943\n",
      "Epoch 233/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0250 - accuracy: 0.9861 - val_loss: 1.0032 - val_accuracy: 0.8935\n",
      "Epoch 234/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0252 - accuracy: 0.9861 - val_loss: 1.0022 - val_accuracy: 0.8940\n",
      "Epoch 235/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0253 - accuracy: 0.9861 - val_loss: 1.0039 - val_accuracy: 0.8933\n",
      "Epoch 236/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0258 - accuracy: 0.9859 - val_loss: 1.0084 - val_accuracy: 0.8932\n",
      "Epoch 237/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0263 - accuracy: 0.9860 - val_loss: 1.0023 - val_accuracy: 0.8932\n",
      "Epoch 238/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0262 - accuracy: 0.9860 - val_loss: 1.0049 - val_accuracy: 0.8930\n",
      "Epoch 239/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0257 - accuracy: 0.9860 - val_loss: 0.9969 - val_accuracy: 0.8935\n",
      "Epoch 240/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0250 - accuracy: 0.9861 - val_loss: 1.0042 - val_accuracy: 0.8936\n",
      "Epoch 241/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0246 - accuracy: 0.9861 - val_loss: 0.9996 - val_accuracy: 0.8936\n",
      "Epoch 242/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0245 - accuracy: 0.9861 - val_loss: 1.0041 - val_accuracy: 0.8939\n",
      "Epoch 243/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0244 - accuracy: 0.9860 - val_loss: 1.0092 - val_accuracy: 0.8938\n",
      "Epoch 244/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0245 - accuracy: 0.9861 - val_loss: 1.0147 - val_accuracy: 0.8938\n",
      "Epoch 245/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0247 - accuracy: 0.9860 - val_loss: 1.0110 - val_accuracy: 0.8936\n",
      "Epoch 246/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0249 - accuracy: 0.9860 - val_loss: 1.0097 - val_accuracy: 0.8935\n",
      "Epoch 247/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0251 - accuracy: 0.9861 - val_loss: 1.0130 - val_accuracy: 0.8933\n",
      "Epoch 248/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0260 - accuracy: 0.9859 - val_loss: 1.0122 - val_accuracy: 0.8928\n",
      "Epoch 249/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0269 - accuracy: 0.9859 - val_loss: 1.0140 - val_accuracy: 0.8927\n",
      "Epoch 250/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0263 - accuracy: 0.9859 - val_loss: 1.0140 - val_accuracy: 0.8931\n",
      "Epoch 251/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0253 - accuracy: 0.9861 - val_loss: 1.0097 - val_accuracy: 0.8940\n",
      "Epoch 252/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0246 - accuracy: 0.9861 - val_loss: 1.0070 - val_accuracy: 0.8937\n",
      "Epoch 253/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0243 - accuracy: 0.9861 - val_loss: 1.0082 - val_accuracy: 0.8940\n",
      "Epoch 254/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0241 - accuracy: 0.9861 - val_loss: 1.0148 - val_accuracy: 0.8939\n",
      "Epoch 255/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0242 - accuracy: 0.9861 - val_loss: 1.0235 - val_accuracy: 0.8943\n",
      "Epoch 256/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0244 - accuracy: 0.9862 - val_loss: 1.0161 - val_accuracy: 0.8932\n",
      "Epoch 257/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0250 - accuracy: 0.9861 - val_loss: 1.0184 - val_accuracy: 0.8931\n",
      "Epoch 258/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0268 - accuracy: 0.9858 - val_loss: 1.0244 - val_accuracy: 0.8921\n",
      "Epoch 259/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0270 - accuracy: 0.9857 - val_loss: 1.0179 - val_accuracy: 0.8934\n",
      "Epoch 260/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0259 - accuracy: 0.9859 - val_loss: 1.0140 - val_accuracy: 0.8938\n",
      "Epoch 261/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0249 - accuracy: 0.9860 - val_loss: 1.0198 - val_accuracy: 0.8940\n",
      "Epoch 262/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0243 - accuracy: 0.9861 - val_loss: 1.0269 - val_accuracy: 0.8942\n",
      "Epoch 263/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0241 - accuracy: 0.9862 - val_loss: 1.0215 - val_accuracy: 0.8939\n",
      "Epoch 264/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0240 - accuracy: 0.9861 - val_loss: 1.0286 - val_accuracy: 0.8938\n",
      "Epoch 265/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0240 - accuracy: 0.9861 - val_loss: 1.0325 - val_accuracy: 0.8940\n",
      "Epoch 266/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0243 - accuracy: 0.9861 - val_loss: 1.0188 - val_accuracy: 0.8937\n",
      "Epoch 267/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0247 - accuracy: 0.9860 - val_loss: 1.0275 - val_accuracy: 0.8931\n",
      "Epoch 268/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0253 - accuracy: 0.9860 - val_loss: 1.0249 - val_accuracy: 0.8934\n",
      "Epoch 269/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0257 - accuracy: 0.9860 - val_loss: 1.0251 - val_accuracy: 0.8927\n",
      "Epoch 270/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0261 - accuracy: 0.9859 - val_loss: 1.0242 - val_accuracy: 0.8929\n",
      "Epoch 271/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0259 - accuracy: 0.9859 - val_loss: 1.0268 - val_accuracy: 0.8932\n",
      "Epoch 272/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0251 - accuracy: 0.9860 - val_loss: 1.0267 - val_accuracy: 0.8923\n",
      "Epoch 273/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0244 - accuracy: 0.9861 - val_loss: 1.0285 - val_accuracy: 0.8934\n",
      "Epoch 274/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0242 - accuracy: 0.9861 - val_loss: 1.0238 - val_accuracy: 0.8929\n",
      "Epoch 275/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0242 - accuracy: 0.9861 - val_loss: 1.0352 - val_accuracy: 0.8933\n",
      "Epoch 276/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0241 - accuracy: 0.9862 - val_loss: 1.0296 - val_accuracy: 0.8936\n",
      "Epoch 277/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0242 - accuracy: 0.9861 - val_loss: 1.0288 - val_accuracy: 0.8933\n",
      "Epoch 278/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0245 - accuracy: 0.9860 - val_loss: 1.0360 - val_accuracy: 0.8934\n",
      "Epoch 279/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0247 - accuracy: 0.9861 - val_loss: 1.0302 - val_accuracy: 0.8926\n",
      "Epoch 280/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0252 - accuracy: 0.9861 - val_loss: 1.0411 - val_accuracy: 0.8930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0255 - accuracy: 0.9860 - val_loss: 1.0324 - val_accuracy: 0.8925\n",
      "Epoch 282/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0257 - accuracy: 0.9859 - val_loss: 1.0363 - val_accuracy: 0.8926\n",
      "Epoch 283/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0255 - accuracy: 0.9859 - val_loss: 1.0217 - val_accuracy: 0.8917\n",
      "Epoch 284/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0249 - accuracy: 0.9860 - val_loss: 1.0374 - val_accuracy: 0.8928\n",
      "Epoch 285/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0242 - accuracy: 0.9861 - val_loss: 1.0287 - val_accuracy: 0.8929\n",
      "Epoch 286/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0238 - accuracy: 0.9862 - val_loss: 1.0344 - val_accuracy: 0.8934\n",
      "Epoch 287/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0238 - accuracy: 0.9862 - val_loss: 1.0325 - val_accuracy: 0.8937\n",
      "Epoch 288/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0239 - accuracy: 0.9860 - val_loss: 1.0351 - val_accuracy: 0.8930\n",
      "Epoch 289/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0241 - accuracy: 0.9861 - val_loss: 1.0463 - val_accuracy: 0.8933\n",
      "Epoch 290/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0243 - accuracy: 0.9860 - val_loss: 1.0362 - val_accuracy: 0.8935\n",
      "Epoch 291/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0246 - accuracy: 0.9861 - val_loss: 1.0518 - val_accuracy: 0.8926\n",
      "Epoch 292/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0251 - accuracy: 0.9860 - val_loss: 1.0523 - val_accuracy: 0.8915\n",
      "Epoch 293/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0262 - accuracy: 0.9859 - val_loss: 1.0436 - val_accuracy: 0.8916\n",
      "Epoch 294/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0261 - accuracy: 0.9858 - val_loss: 1.0478 - val_accuracy: 0.8922\n",
      "Epoch 295/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0250 - accuracy: 0.9860 - val_loss: 1.0420 - val_accuracy: 0.8926\n",
      "Epoch 296/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0244 - accuracy: 0.9861 - val_loss: 1.0409 - val_accuracy: 0.8924\n",
      "Epoch 297/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0240 - accuracy: 0.9861 - val_loss: 1.0496 - val_accuracy: 0.8929\n",
      "Epoch 298/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0237 - accuracy: 0.9861 - val_loss: 1.0491 - val_accuracy: 0.8929\n",
      "Epoch 299/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0236 - accuracy: 0.9862 - val_loss: 1.0513 - val_accuracy: 0.8929\n",
      "Epoch 300/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0237 - accuracy: 0.9861 - val_loss: 1.0507 - val_accuracy: 0.8930\n",
      "Epoch 301/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0239 - accuracy: 0.9861 - val_loss: 1.0514 - val_accuracy: 0.8934\n",
      "Epoch 302/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0242 - accuracy: 0.9861 - val_loss: 1.0542 - val_accuracy: 0.8926\n",
      "Epoch 303/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0246 - accuracy: 0.9861 - val_loss: 1.0530 - val_accuracy: 0.8922\n",
      "Epoch 304/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0255 - accuracy: 0.9859 - val_loss: 1.0495 - val_accuracy: 0.8913\n",
      "Epoch 305/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0266 - accuracy: 0.9858 - val_loss: 1.0552 - val_accuracy: 0.8916\n",
      "Epoch 306/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0259 - accuracy: 0.9859 - val_loss: 1.0464 - val_accuracy: 0.8917\n",
      "Epoch 307/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0248 - accuracy: 0.9860 - val_loss: 1.0583 - val_accuracy: 0.8923\n",
      "Epoch 308/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0243 - accuracy: 0.9859 - val_loss: 1.0575 - val_accuracy: 0.8926\n",
      "Epoch 309/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0238 - accuracy: 0.9860 - val_loss: 1.0619 - val_accuracy: 0.8930\n",
      "Epoch 310/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0235 - accuracy: 0.9862 - val_loss: 1.0570 - val_accuracy: 0.8931\n",
      "Epoch 311/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0235 - accuracy: 0.9861 - val_loss: 1.0567 - val_accuracy: 0.8929\n",
      "Epoch 312/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0236 - accuracy: 0.9861 - val_loss: 1.0585 - val_accuracy: 0.8931\n",
      "Epoch 313/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0238 - accuracy: 0.9861 - val_loss: 1.0645 - val_accuracy: 0.8932\n",
      "Epoch 314/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0242 - accuracy: 0.9860 - val_loss: 1.0624 - val_accuracy: 0.8923\n",
      "Epoch 315/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0250 - accuracy: 0.9860 - val_loss: 1.0556 - val_accuracy: 0.8921\n",
      "Epoch 316/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0262 - accuracy: 0.9858 - val_loss: 1.0690 - val_accuracy: 0.8918\n",
      "Epoch 317/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0263 - accuracy: 0.9858 - val_loss: 1.0617 - val_accuracy: 0.8916\n",
      "Epoch 318/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0254 - accuracy: 0.9859 - val_loss: 1.0640 - val_accuracy: 0.8923\n",
      "Epoch 319/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0244 - accuracy: 0.9861 - val_loss: 1.0664 - val_accuracy: 0.8923\n",
      "Epoch 320/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0237 - accuracy: 0.9861 - val_loss: 1.0637 - val_accuracy: 0.8933\n",
      "Epoch 321/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0234 - accuracy: 0.9861 - val_loss: 1.0629 - val_accuracy: 0.8928\n",
      "Epoch 322/600\n",
      "493/493 [==============================] - 26s 54ms/step - loss: 0.0234 - accuracy: 0.9861 - val_loss: 1.0682 - val_accuracy: 0.8927\n",
      "Epoch 323/600\n",
      "493/493 [==============================] - 28s 56ms/step - loss: 0.0234 - accuracy: 0.9860 - val_loss: 1.0715 - val_accuracy: 0.8927\n",
      "Epoch 324/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0236 - accuracy: 0.9861 - val_loss: 1.0783 - val_accuracy: 0.8925\n",
      "Epoch 325/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0239 - accuracy: 0.9860 - val_loss: 1.0677 - val_accuracy: 0.8919\n",
      "Epoch 326/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0243 - accuracy: 0.9860 - val_loss: 1.0755 - val_accuracy: 0.8919\n",
      "Epoch 327/600\n",
      "493/493 [==============================] - 27s 54ms/step - loss: 0.0260 - accuracy: 0.9858 - val_loss: 1.0694 - val_accuracy: 0.8913\n",
      "Epoch 328/600\n",
      "493/493 [==============================] - 27s 55ms/step - loss: 0.0271 - accuracy: 0.9856 - val_loss: 1.0622 - val_accuracy: 0.8910\n",
      "Epoch 329/600\n",
      "493/493 [==============================] - 27s 55ms/step - loss: 0.0256 - accuracy: 0.9859 - val_loss: 1.0641 - val_accuracy: 0.8920\n",
      "Epoch 330/600\n",
      "493/493 [==============================] - 28s 57ms/step - loss: 0.0244 - accuracy: 0.9860 - val_loss: 1.0654 - val_accuracy: 0.8919\n",
      "Epoch 331/600\n",
      "493/493 [==============================] - 28s 56ms/step - loss: 0.0238 - accuracy: 0.9861 - val_loss: 1.0617 - val_accuracy: 0.8925\n",
      "Epoch 332/600\n",
      "493/493 [==============================] - 28s 56ms/step - loss: 0.0235 - accuracy: 0.9862 - val_loss: 1.0715 - val_accuracy: 0.8928\n",
      "Epoch 333/600\n",
      "493/493 [==============================] - 28s 57ms/step - loss: 0.0234 - accuracy: 0.9860 - val_loss: 1.0653 - val_accuracy: 0.8928\n",
      "Epoch 334/600\n",
      "493/493 [==============================] - 30s 61ms/step - loss: 0.0233 - accuracy: 0.9861 - val_loss: 1.0729 - val_accuracy: 0.8927\n",
      "Epoch 335/600\n",
      "493/493 [==============================] - 31s 63ms/step - loss: 0.0235 - accuracy: 0.9861 - val_loss: 1.0760 - val_accuracy: 0.8929\n",
      "Epoch 336/600\n",
      "493/493 [==============================] - 32s 65ms/step - loss: 0.0237 - accuracy: 0.9861 - val_loss: 1.0718 - val_accuracy: 0.8926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/600\n",
      "493/493 [==============================] - 30s 61ms/step - loss: 0.0242 - accuracy: 0.9861 - val_loss: 1.0674 - val_accuracy: 0.8924\n",
      "Epoch 338/600\n",
      "493/493 [==============================] - 31s 63ms/step - loss: 0.0250 - accuracy: 0.9860 - val_loss: 1.0676 - val_accuracy: 0.8914\n",
      "Epoch 339/600\n",
      "493/493 [==============================] - 30s 60ms/step - loss: 0.0267 - accuracy: 0.9856 - val_loss: 1.0737 - val_accuracy: 0.8908\n",
      "Epoch 340/600\n",
      "493/493 [==============================] - 30s 60ms/step - loss: 0.0265 - accuracy: 0.9857 - val_loss: 1.0711 - val_accuracy: 0.8914\n",
      "Epoch 341/600\n",
      "493/493 [==============================] - 32s 64ms/step - loss: 0.0249 - accuracy: 0.9859 - val_loss: 1.0734 - val_accuracy: 0.8918\n",
      "Epoch 342/600\n",
      "493/493 [==============================] - 31s 63ms/step - loss: 0.0238 - accuracy: 0.9861 - val_loss: 1.0687 - val_accuracy: 0.8920\n",
      "Epoch 343/600\n",
      "493/493 [==============================] - 31s 62ms/step - loss: 0.0234 - accuracy: 0.9860 - val_loss: 1.0696 - val_accuracy: 0.8925\n",
      "Epoch 344/600\n",
      "493/493 [==============================] - 30s 61ms/step - loss: 0.0233 - accuracy: 0.9861 - val_loss: 1.0781 - val_accuracy: 0.8927\n",
      "Epoch 345/600\n",
      "493/493 [==============================] - 31s 63ms/step - loss: 0.0232 - accuracy: 0.9861 - val_loss: 1.0735 - val_accuracy: 0.8922\n",
      "Epoch 346/600\n",
      "493/493 [==============================] - 31s 62ms/step - loss: 0.0233 - accuracy: 0.9862 - val_loss: 1.0795 - val_accuracy: 0.8925\n",
      "Epoch 347/600\n",
      "493/493 [==============================] - 30s 61ms/step - loss: 0.0235 - accuracy: 0.9862 - val_loss: 1.0814 - val_accuracy: 0.8925\n",
      "Epoch 348/600\n",
      "493/493 [==============================] - 30s 60ms/step - loss: 0.0239 - accuracy: 0.9861 - val_loss: 1.0891 - val_accuracy: 0.8924\n",
      "Epoch 349/600\n",
      "493/493 [==============================] - 30s 60ms/step - loss: 0.0253 - accuracy: 0.9859 - val_loss: 1.0850 - val_accuracy: 0.8915\n",
      "Epoch 350/600\n",
      "493/493 [==============================] - 32s 64ms/step - loss: 0.0269 - accuracy: 0.9856 - val_loss: 1.0765 - val_accuracy: 0.8909\n",
      "Epoch 351/600\n",
      "493/493 [==============================] - 31s 63ms/step - loss: 0.0262 - accuracy: 0.9858 - val_loss: 1.0803 - val_accuracy: 0.8916\n",
      "Epoch 352/600\n",
      "493/493 [==============================] - 31s 62ms/step - loss: 0.0248 - accuracy: 0.9860 - val_loss: 1.0782 - val_accuracy: 0.8917\n",
      "Epoch 353/600\n",
      "493/493 [==============================] - 30s 61ms/step - loss: 0.0238 - accuracy: 0.9861 - val_loss: 1.0763 - val_accuracy: 0.8923\n",
      "Epoch 354/600\n",
      "493/493 [==============================] - 31s 63ms/step - loss: 0.0234 - accuracy: 0.9861 - val_loss: 1.0821 - val_accuracy: 0.8922\n",
      "Epoch 355/600\n",
      "493/493 [==============================] - 33s 68ms/step - loss: 0.0232 - accuracy: 0.9862 - val_loss: 1.0766 - val_accuracy: 0.8924\n",
      "Epoch 356/600\n",
      "493/493 [==============================] - 30s 60ms/step - loss: 0.0233 - accuracy: 0.9862 - val_loss: 1.0800 - val_accuracy: 0.8925\n",
      "Epoch 357/600\n",
      "493/493 [==============================] - 29s 59ms/step - loss: 0.0233 - accuracy: 0.9861 - val_loss: 1.0840 - val_accuracy: 0.8921\n",
      "Epoch 358/600\n",
      "493/493 [==============================] - 31s 63ms/step - loss: 0.0234 - accuracy: 0.9861 - val_loss: 1.0912 - val_accuracy: 0.8925\n",
      "Epoch 359/600\n",
      "493/493 [==============================] - 30s 60ms/step - loss: 0.0239 - accuracy: 0.9860 - val_loss: 1.0805 - val_accuracy: 0.8920\n",
      "Epoch 360/600\n",
      "493/493 [==============================] - 29s 59ms/step - loss: 0.0248 - accuracy: 0.9861 - val_loss: 1.0908 - val_accuracy: 0.8915\n",
      "Epoch 361/600\n",
      "493/493 [==============================] - 29s 59ms/step - loss: 0.0262 - accuracy: 0.9857 - val_loss: 1.0861 - val_accuracy: 0.8907\n",
      "Epoch 362/600\n",
      "493/493 [==============================] - 28s 57ms/step - loss: 0.0265 - accuracy: 0.9857 - val_loss: 1.0891 - val_accuracy: 0.8916\n",
      "Epoch 363/600\n",
      "493/493 [==============================] - 31s 62ms/step - loss: 0.0251 - accuracy: 0.9859 - val_loss: 1.0819 - val_accuracy: 0.8917\n",
      "Epoch 364/600\n",
      "493/493 [==============================] - 34s 70ms/step - loss: 0.0241 - accuracy: 0.9861 - val_loss: 1.0889 - val_accuracy: 0.8925\n",
      "Epoch 365/600\n",
      "493/493 [==============================] - 34s 68ms/step - loss: 0.0235 - accuracy: 0.9860 - val_loss: 1.0833 - val_accuracy: 0.8922\n",
      "Epoch 366/600\n",
      "493/493 [==============================] - 32s 66ms/step - loss: 0.0232 - accuracy: 0.9861 - val_loss: 1.0839 - val_accuracy: 0.8927\n",
      "Epoch 367/600\n",
      "493/493 [==============================] - 33s 67ms/step - loss: 0.0231 - accuracy: 0.9861 - val_loss: 1.0792 - val_accuracy: 0.8923\n",
      "Epoch 368/600\n",
      "493/493 [==============================] - 174s 353ms/step - loss: 0.0232 - accuracy: 0.9862 - val_loss: 1.0932 - val_accuracy: 0.8926\n",
      "Epoch 369/600\n",
      "160/493 [========>.....................] - ETA: 39s - loss: 0.0199 - accuracy: 0.9885"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "\"\"\"\n",
    "es = EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", verbose=1, patience=4)\n",
    "mc = ModelCheckpoint(\"Models/best_Seq2seq_model.h5\", monitor=\"val_accuracy\", mode=\"max\", verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), batch_size=128, epochs=100, callbacks=[es, mc])\n",
    "\"\"\"\n",
    "\n",
    "model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), batch_size=128, epochs=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = load_model(\"Models/best_Seq2seq_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder\n",
    "encoder_model = Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoder\n",
    "decoder_state_input_h = Input(shape=(hidden_units,))\n",
    "decoder_state_input_c = Input(shape=(hidden_units,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs) #Shared layer\n",
    "\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Activating Decoder\n",
    "def decode_sequence(input_seq) :\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0,0] = tar_to_index[\"<sos>\"]\n",
    "    \n",
    "    decoded_sentence = ''\n",
    "    stop_condition = True\n",
    "    \n",
    "    while stop_condition :\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        \n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :]) #가장 마지막 행 전체\n",
    "        sampled_char = index_to_tar[sampled_token_index]\n",
    "        \n",
    "        decoded_sentence += ' ' + sampled_char\n",
    "        \n",
    "        if (sampled_char == '<eos>' or len(decoded_sentence) > 50) :\n",
    "            stop_condition = False\n",
    "        \n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0,0] = sampled_token_index\n",
    "        \n",
    "        sates_value = [h, c]\n",
    "        \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_to_src(input_seq):\n",
    "    sentence = ''\n",
    "    for encoded_word in input_seq:\n",
    "        if(encoded_word != 0):\n",
    "            sentence = sentence + index_to_src[encoded_word] + ' '\n",
    "            \n",
    "    return sentence\n",
    "\n",
    "def seq_to_tar(input_seq):\n",
    "    sentence = ''\n",
    "    for encoded_word in input_seq:\n",
    "        if(encoded_word != 0 and encoded_word != tar_to_index['<sos>'] and encoded_word != tar_to_index['<eos>']):\n",
    "            sentence = sentence + index_to_tar[encoded_word] + ' '\n",
    "            \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq_index in [3, 100, 300, 500, 2001]:\n",
    "    input_seq = encoder_input_train[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "\n",
    "    print(\"Input sentence :\",seq_to_src(encoder_input_train[seq_index]))\n",
    "    print(\"Correct sentence :\",seq_to_tar(decoder_input_train[seq_index]))\n",
    "    print(\"Output sentence :\",decoded_sentence)\n",
    "    print(\"-\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
