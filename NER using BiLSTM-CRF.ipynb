{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1OogmnKYPRtYSww8kSyueTwMGYFeznZAl",
      "authorship_tag": "ABX9TyM3U5KDRTyf8dI8a4kdJ2Mq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sion1225/Study-Deeplearning-NLP/blob/master/NER%20using%20BiLSTM-CRF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t7vsnPRY8EG",
        "outputId": "b66f5ce4-4b55-4498-ac98-0225c1abad39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-crf\n",
            "  Downloading keras_crf-0.3.0-py3-none-any.whl (8.3 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (from keras-crf) (2.11.0)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (2.11.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (3.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (1.4.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (0.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (4.5.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (2.2.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (2.11.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (1.14.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (3.19.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (23.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (2.11.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (23.1.21)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (57.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (1.22.4)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (0.30.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (15.0.6.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (1.51.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons->keras-crf) (2.7.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow->keras-crf) (0.38.4)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-crf) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-crf) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-crf) (2.25.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-crf) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-crf) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-crf) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-crf) (2.16.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-crf) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-crf) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-crf) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->keras-crf) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->keras-crf) (6.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-crf) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-crf) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-crf) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-crf) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->keras-crf) (3.13.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-crf) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->keras-crf) (3.2.2)\n",
            "Installing collected packages: tensorflow-addons, keras-crf\n",
            "Successfully installed keras-crf-0.3.0 tensorflow-addons-0.19.0\n"
          ]
        }
      ],
      "source": [
        "pip install keras-crf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataSet: Annotated Corpus for Named Entity Recognition \n",
        "(https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus)\n",
        "\n",
        "Pre-processing process is from \"BIO NER using BiLSTM & F1-score.ipynb\""
      ],
      "metadata": {
        "id": "qNp6_WaZagql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "haljMF0LZGt6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/GitHub/Study-Deeplearning-NLP/DataSet/ner_dataset.csv\", encoding=\"latin1\")"
      ],
      "metadata": {
        "id": "IH2FZY2pazjT"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.fillna(method=\"ffill\")\n",
        "data[\"Word\"] = data[\"Word\"].str.lower()"
      ],
      "metadata": {
        "id": "Y2kyNSEfa0ya"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "func = lambda temp: [(w, t) for w, t in zip(temp[\"Word\"].values.tolist(), temp[\"Tag\"].values.tolist())]\n",
        "tagged_sentences = [t for t in data.groupby(\"Sentence #\").apply(func)]"
      ],
      "metadata": {
        "id": "ZhcktELja_ni"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences, ner_tags = [], []\n",
        "\n",
        "for tagged_sentence in tagged_sentences :\n",
        "    sentence, tag_info = zip(*tagged_sentence)\n",
        "    sentences.append(list(sentence))\n",
        "    ner_tags.append(list(tag_info))"
      ],
      "metadata": {
        "id": "L9URwte8bHmo"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tar_tokenizer = Tokenizer(lower=False)\n",
        "\n",
        "src_tokenizer.fit_on_texts(sentences)\n",
        "tar_tokenizer.fit_on_texts(ner_tags)"
      ],
      "metadata": {
        "id": "YlbmEgr9bKjz"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(src_tokenizer.word_index) + 1\n",
        "tag_size = len(tar_tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "uijLa_bnbN__"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_data = src_tokenizer.texts_to_sequences(sentences)\n",
        "y_data = tar_tokenizer.texts_to_sequences(ner_tags)"
      ],
      "metadata": {
        "id": "XOMul2FjbQ2D"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index = src_tokenizer.word_index\n",
        "index_to_word = src_tokenizer.index_word\n",
        "ner_to_index = tar_tokenizer.word_index\n",
        "index_to_ner = tar_tokenizer.index_word\n",
        "\n",
        "index_to_ner[0] = \"PAD\" # 0 for padding"
      ],
      "metadata": {
        "id": "bIlwNK2MbU39"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 70\n",
        "X_data = pad_sequences(X_data, padding=\"post\", maxlen=max_len)\n",
        "y_data = pad_sequences(y_data, padding=\"post\", maxlen=max_len)"
      ],
      "metadata": {
        "id": "AXCSx3xabWHo"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train_int, y_test_int  = train_test_split(X_data, y_data, test_size=.2, random_state=1225)"
      ],
      "metadata": {
        "id": "LNryDuI4bbA7"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train_int, num_classes=tag_size)\n",
        "y_test = to_categorical(y_test_int, num_classes=tag_size)"
      ],
      "metadata": {
        "id": "L1psv_ISbcbd"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of training sentences sample : \", X_train.shape)\n",
        "print(\"Shape of training label sample : \", y_train_int.shape)\n",
        "print(\"Shape of test sentences sample : \", X_test.shape)\n",
        "print(\"Shape of test label sample : \", y_test_int.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1V8rjdibgT6",
        "outputId": "0f8ea21d-f95f-4826-a4d9-d679b22f6244"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training sentences sample :  (38367, 70)\n",
            "Shape of training label sample :  (38367, 70)\n",
            "Shape of test sentences sample :  (9592, 70)\n",
            "Shape of test label sample :  (9592, 70)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKpBr6V-_D3n",
        "outputId": "cedf721d-babf-4434-84c0-948fbe936447"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(38367, 70, 18)\n",
            "(9592, 70, 18)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model (BiLSTM-CRF)"
      ],
      "metadata": {
        "id": "kRJFOrpAblB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6N7Vu6Kfb7z",
        "outputId": "39ef0d82-186e-402e-88e3-dc3c06774938"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from seqeval) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16179 sha256=50df1b59cb7a2c075b0b02b671b21d0b47c6f93fa43e55e27a36dbaaec9d74f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense, LSTM, Input, Bidirectional, TimeDistributed, Embedding, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras_crf import CRFModel\n",
        "from seqeval.metrics import f1_score, classification_report"
      ],
      "metadata": {
        "id": "Ij4Y2mjgbiBU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 128\n",
        "hidden_units = 64\n",
        "dropout_ratio = 0.3"
      ],
      "metadata": {
        "id": "s9xMmmZHfXGy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_input = Input(shape=(max_len,), dtype=tf.int32, name=\"sequence_input\")\n",
        "hidden = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len)(sequence_input)\n",
        "hidden = Bidirectional(LSTM(units=hidden_units, return_sequences=True))(hidden)\n",
        "hidden = TimeDistributed(Dropout(dropout_ratio))(hidden)\n",
        "BiLSTM_ouputs = TimeDistributed(Dense(tag_size, activation='relu'))(hidden)\n",
        "base = Model(sequence_input, BiLSTM_ouputs)\n",
        "model = CRFModel(base, tag_size)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Nadam(0.001), metrics=\"accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvzTkn3ngGjM",
        "outputId": "6b407130-ca71-4545-b22a-79426fa2030e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=4)\n",
        "mc = ModelCheckpoint(\"/content/drive/MyDrive/GitHub/Study-Deeplearning-NLP/Models/BiLSTM_CRF.ckpt\", monitor=\"val_decode_sequence_accuracy\", mode=\"max\", verbose=1, save_best_only=True, save_weights_only=True)"
      ],
      "metadata": {
        "id": "dIi3Fl_EhzFW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train_int, batch_size=128, epochs=15, validation_split=0.1, callbacks=[mc, es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hY45qZVhyvFt",
        "outputId": "fa2c2d6c-31e9-4705-d692-0fea1e9fb9ad"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9096 - loss: 29.2804\n",
            "Epoch 1: val_decode_sequence_accuracy improved from -inf to 0.96019, saving model to /content/drive/MyDrive/GitHub/Study-Deeplearning-NLP/Models/BiLSTM_CRF.ckpt\n",
            "270/270 [==============================] - 89s 266ms/step - decode_sequence_accuracy: 0.9096 - loss: 29.2104 - val_decode_sequence_accuracy: 0.9602 - val_loss: 9.7232\n",
            "Epoch 2/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9708 - loss: 6.7673\n",
            "Epoch 2: val_decode_sequence_accuracy improved from 0.96019 to 0.98047, saving model to /content/drive/MyDrive/GitHub/Study-Deeplearning-NLP/Models/BiLSTM_CRF.ckpt\n",
            "270/270 [==============================] - 49s 182ms/step - decode_sequence_accuracy: 0.9708 - loss: 6.7591 - val_decode_sequence_accuracy: 0.9805 - val_loss: 5.2175\n",
            "Epoch 3/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9824 - loss: 3.9013\n",
            "Epoch 3: val_decode_sequence_accuracy improved from 0.98047 to 0.98452, saving model to /content/drive/MyDrive/GitHub/Study-Deeplearning-NLP/Models/BiLSTM_CRF.ckpt\n",
            "270/270 [==============================] - 56s 209ms/step - decode_sequence_accuracy: 0.9824 - loss: 3.8995 - val_decode_sequence_accuracy: 0.9845 - val_loss: 3.7851\n",
            "Epoch 4/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9866 - loss: 2.7154\n",
            "Epoch 4: val_decode_sequence_accuracy improved from 0.98452 to 0.98548, saving model to /content/drive/MyDrive/GitHub/Study-Deeplearning-NLP/Models/BiLSTM_CRF.ckpt\n",
            "270/270 [==============================] - 45s 167ms/step - decode_sequence_accuracy: 0.9866 - loss: 2.7144 - val_decode_sequence_accuracy: 0.9855 - val_loss: 3.2040\n",
            "Epoch 5/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9885 - loss: 2.1305\n",
            "Epoch 5: val_decode_sequence_accuracy improved from 0.98548 to 0.98588, saving model to /content/drive/MyDrive/GitHub/Study-Deeplearning-NLP/Models/BiLSTM_CRF.ckpt\n",
            "270/270 [==============================] - 47s 175ms/step - decode_sequence_accuracy: 0.9885 - loss: 2.1300 - val_decode_sequence_accuracy: 0.9859 - val_loss: 3.1114\n",
            "Epoch 6/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9898 - loss: 1.7801\n",
            "Epoch 6: val_decode_sequence_accuracy improved from 0.98588 to 0.98599, saving model to /content/drive/MyDrive/GitHub/Study-Deeplearning-NLP/Models/BiLSTM_CRF.ckpt\n",
            "270/270 [==============================] - 45s 165ms/step - decode_sequence_accuracy: 0.9898 - loss: 1.7790 - val_decode_sequence_accuracy: 0.9860 - val_loss: 3.1106\n",
            "Epoch 7/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9907 - loss: 1.5432\n",
            "Epoch 7: val_decode_sequence_accuracy did not improve from 0.98599\n",
            "270/270 [==============================] - 43s 161ms/step - decode_sequence_accuracy: 0.9907 - loss: 1.5423 - val_decode_sequence_accuracy: 0.9860 - val_loss: 3.0298\n",
            "Epoch 8/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9914 - loss: 1.3581\n",
            "Epoch 8: val_decode_sequence_accuracy did not improve from 0.98599\n",
            "270/270 [==============================] - 44s 163ms/step - decode_sequence_accuracy: 0.9914 - loss: 1.3574 - val_decode_sequence_accuracy: 0.9858 - val_loss: 3.0767\n",
            "Epoch 9/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9921 - loss: 1.2033\n",
            "Epoch 9: val_decode_sequence_accuracy did not improve from 0.98599\n",
            "270/270 [==============================] - 44s 163ms/step - decode_sequence_accuracy: 0.9921 - loss: 1.2038 - val_decode_sequence_accuracy: 0.9856 - val_loss: 3.2831\n",
            "Epoch 10/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9926 - loss: 1.0741\n",
            "Epoch 10: val_decode_sequence_accuracy did not improve from 0.98599\n",
            "270/270 [==============================] - 44s 162ms/step - decode_sequence_accuracy: 0.9926 - loss: 1.0741 - val_decode_sequence_accuracy: 0.9855 - val_loss: 3.3601\n",
            "Epoch 11/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9931 - loss: 0.9618\n",
            "Epoch 11: val_decode_sequence_accuracy did not improve from 0.98599\n",
            "270/270 [==============================] - 43s 159ms/step - decode_sequence_accuracy: 0.9931 - loss: 0.9624 - val_decode_sequence_accuracy: 0.9849 - val_loss: 3.3725\n",
            "Epoch 11: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(\"/content/drive/MyDrive/GitHub/Study-Deeplearning-NLP/Models/BiLSTM_CRF.ckpt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUIy1bkCy8Bi",
        "outputId": "e7f28e62-2414-448a-e1ab-b460eb14bd86"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fc36cfdbd60>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 10\n",
        "y_predicted = model.predict(np.array([X_test[i]]))[0]\n",
        "labels = np.argmax(y_test[i], -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0liPQK94Z-E",
        "outputId": "1a03d9a3-f63c-46a0-972e-f0e1c11a2a07"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 106ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_predicted[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5Q_GL1j5t4P",
        "outputId": "2ab8c240-f5e6-4a23-9ad0-aee73b306212"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1  1  6  1  6  5  4  7  1  1  1  1  1  1  1  3 10 10 10  1  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"{:15}|{:12}|{}\".format(\"Voca\",\"Real Value\", \"Predicted\"))\n",
        "for word, tag, pred in zip(X_test[i], labels, y_predicted[0]) :\n",
        "    if word != 0 :\n",
        "        print(\"{:15}|{:12}|{}\".format(index_to_word[word], index_to_ner[tag], index_to_ner[pred]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqcG6YjW5Oxb",
        "outputId": "65605883-43da-433b-965c-335d01be9936"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voca           |Real Value  |Predicted\n",
            "the            |O           |O\n",
            "\"              |O           |O\n",
            "roe            |B-per       |B-per\n",
            "versus         |O           |O\n",
            "wade           |B-per       |B-per\n",
            "\"              |O           |I-per\n",
            "supreme        |B-org       |B-org\n",
            "court          |I-org       |I-org\n",
            "decision       |O           |O\n",
            "legalizing     |O           |O\n",
            "abortion       |O           |O\n",
            "was            |O           |O\n",
            "handed         |O           |O\n",
            "down           |O           |O\n",
            "on             |O           |O\n",
            "january        |B-tim       |B-tim\n",
            "22             |I-tim       |I-tim\n",
            ",              |I-tim       |I-tim\n",
            "1973           |I-tim       |I-tim\n",
            ".              |O           |O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#F1-score\n",
        "f1 score = 2 * { (precision * recall) / (precision+recall) }"
      ],
      "metadata": {
        "id": "SxQhcSD-6O9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from seqeval.metrics import f1_score, classification_report"
      ],
      "metadata": {
        "id": "iOZy_E-cAj-Z"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted = model.predict(X_test)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE1Ax5DgCktQ",
        "outputId": "c03478a9-c67f-40cc-ac96-dadca33afbe9"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300/300 [==============================] - 16s 53ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sequences_to_tag(sequences) :\n",
        "    result = []\n",
        "\n",
        "    for sequence in sequences :\n",
        "        word_sequence = []\n",
        "\n",
        "        for pred in sequence :\n",
        "            pred_index = np.argmax(pred)\n",
        "            word_sequence.append(index_to_ner[pred_index].replace(\"PAD\",\"O\"))\n",
        "\n",
        "        result.append(word_sequence)\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "bkt4Y5sY_pQY"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sequences_to_tag_for_crf(sequences) :\n",
        "    result = []\n",
        "\n",
        "    for sequence in sequences :\n",
        "        word_sequence = []\n",
        "        \n",
        "        for pred_index in sequence :\n",
        "            word_sequence.append(index_to_ner[pred_index].replace(\"PAD\", \"O\"))\n",
        "        \n",
        "        result.append(word_sequence)\n",
        "    \n",
        "    return result"
      ],
      "metadata": {
        "id": "BcfrpzFW5qPD"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_tags = sequences_to_tag_for_crf(y_predicted)\n",
        "test_tags = sequences_to_tag(y_test)"
      ],
      "metadata": {
        "id": "EMY2Ixw1-hCe"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_predicted[10])\n",
        "print(y_test[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3DJQiGQBAkH",
        "outputId": "1b691cc4-5cde-414b-9b3c-5d5e0dd48864"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1  1  6  1  6  5  4  7  1  1  1  1  1  1  1  3 10 10 10  1  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[[0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pred_tags[10])\n",
        "print(test_tags[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdgZ7jKsAOn4",
        "outputId": "f14f3d41-0f2c-4d4b-889e-a31b468277fc"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['O', 'O', 'B-per', 'O', 'B-per', 'I-per', 'B-org', 'I-org', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-tim', 'I-tim', 'I-tim', 'I-tim', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "['O', 'O', 'B-per', 'O', 'B-per', 'O', 'B-org', 'I-org', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-tim', 'I-tim', 'I-tim', 'I-tim', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"F1-score: {:.2%}\".format(f1_score(test_tags, pred_tags)))\n",
        "print(classification_report(test_tags, pred_tags))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yY2Sqixs_qdA",
        "outputId": "77a2b56d-6d41-4769-8da9-a717dd547858"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score: 79.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.00      0.00      0.00        91\n",
            "         eve       0.00      0.00      0.00        59\n",
            "         geo       0.82      0.87      0.84      7390\n",
            "         gpe       0.94      0.92      0.93      3166\n",
            "         nat       1.00      0.07      0.12        30\n",
            "         org       0.67      0.56      0.61      4004\n",
            "         per       0.73      0.69      0.71      3336\n",
            "         tim       0.87      0.83      0.85      4032\n",
            "\n",
            "   micro avg       0.81      0.78      0.79     22108\n",
            "   macro avg       0.63      0.49      0.51     22108\n",
            "weighted avg       0.80      0.78      0.79     22108\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vOLGoK6e_toa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}