{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1OogmnKYPRtYSww8kSyueTwMGYFeznZAl",
      "authorship_tag": "ABX9TyNhwS7OXe7UyN4nGF04nJBM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sion1225/Study-Deeplearning-NLP/blob/master/NER%20using%20BiLSTM-CRF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t7vsnPRY8EG",
        "outputId": "b66f5ce4-4b55-4498-ac98-0225c1abad39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-crf\n",
            "  Downloading keras_crf-0.3.0-py3-none-any.whl (8.3 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (from keras-crf) (2.11.0)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (2.11.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (3.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (1.4.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (0.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (4.5.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (2.2.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (2.11.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (1.14.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (3.19.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (23.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (2.11.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (23.1.21)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (57.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (1.22.4)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (0.30.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (15.0.6.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-crf) (1.51.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons->keras-crf) (2.7.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow->keras-crf) (0.38.4)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-crf) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-crf) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-crf) (2.25.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-crf) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-crf) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-crf) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-crf) (2.16.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-crf) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-crf) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-crf) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->keras-crf) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->keras-crf) (6.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-crf) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-crf) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-crf) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-crf) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->keras-crf) (3.13.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-crf) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->keras-crf) (3.2.2)\n",
            "Installing collected packages: tensorflow-addons, keras-crf\n",
            "Successfully installed keras-crf-0.3.0 tensorflow-addons-0.19.0\n"
          ]
        }
      ],
      "source": [
        "pip install keras-crf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataSet: Annotated Corpus for Named Entity Recognition \n",
        "(https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus)\n",
        "\n",
        "Pre-processing process is from \"BIO NER using BiLSTM & F1-score.ipynb\""
      ],
      "metadata": {
        "id": "qNp6_WaZagql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "haljMF0LZGt6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/GitHub/Study-Deeplearning-NLP/DataSet/ner_dataset.csv\", encoding=\"latin1\")"
      ],
      "metadata": {
        "id": "IH2FZY2pazjT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.fillna(method=\"ffill\")\n",
        "data[\"Word\"] = data[\"Word\"].str.lower()"
      ],
      "metadata": {
        "id": "Y2kyNSEfa0ya"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "func = lambda temp: [(w, t) for w, t in zip(temp[\"Word\"].values.tolist(), temp[\"Tag\"].values.tolist())]\n",
        "tagged_sentences = [t for t in data.groupby(\"Sentence #\").apply(func)]"
      ],
      "metadata": {
        "id": "ZhcktELja_ni"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences, ner_tags = [], []\n",
        "\n",
        "for tagged_sentence in tagged_sentences :\n",
        "    sentence, tag_info = zip(*tagged_sentence)\n",
        "    sentences.append(list(sentence))\n",
        "    ner_tags.append(list(tag_info))"
      ],
      "metadata": {
        "id": "L9URwte8bHmo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tar_tokenizer = Tokenizer(lower=False)\n",
        "\n",
        "src_tokenizer.fit_on_texts(sentences)\n",
        "tar_tokenizer.fit_on_texts(ner_tags)"
      ],
      "metadata": {
        "id": "YlbmEgr9bKjz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(src_tokenizer.word_index) + 1\n",
        "tag_size = len(tar_tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "uijLa_bnbN__"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_data = src_tokenizer.texts_to_sequences(sentences)\n",
        "y_data = tar_tokenizer.texts_to_sequences(ner_tags)"
      ],
      "metadata": {
        "id": "XOMul2FjbQ2D"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index = src_tokenizer.word_index\n",
        "index_to_word = src_tokenizer.index_word\n",
        "ner_to_index = tar_tokenizer.word_index\n",
        "index_to_ner = tar_tokenizer.index_word\n",
        "\n",
        "index_to_ner[0] = \"PAD\" # 0 for padding"
      ],
      "metadata": {
        "id": "bIlwNK2MbU39"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 70\n",
        "X_data = pad_sequences(X_data, padding=\"post\", maxlen=max_len)\n",
        "y_data = pad_sequences(y_data, padding=\"post\", maxlen=max_len)"
      ],
      "metadata": {
        "id": "AXCSx3xabWHo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train_int, y_test_int  = train_test_split(X_data, y_data, test_size=.2, random_state=1225)"
      ],
      "metadata": {
        "id": "LNryDuI4bbA7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train_int, num_classes=tag_size)\n",
        "y_test = to_categorical(y_test_int, num_classes=tag_size)"
      ],
      "metadata": {
        "id": "L1psv_ISbcbd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of training sentences sample : \", X_train.shape)\n",
        "print(\"Shape of training label sample : \", y_train_int.shape)\n",
        "print(\"Shape of test sentences sample : \", X_test.shape)\n",
        "print(\"Shape of test label sample : \", y_test_int.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1V8rjdibgT6",
        "outputId": "3e12b558-0b86-4f4a-ab7c-290d3199c62d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training sentences sample :  (38367, 70)\n",
            "Shape of training label sample :  (38367, 70)\n",
            "Shape of test sentences sample :  (9592, 70)\n",
            "Shape of test label sample :  (9592, 70)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model (BiLSTM-CRF)"
      ],
      "metadata": {
        "id": "kRJFOrpAblB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6N7Vu6Kfb7z",
        "outputId": "39ef0d82-186e-402e-88e3-dc3c06774938"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from seqeval) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16179 sha256=50df1b59cb7a2c075b0b02b671b21d0b47c6f93fa43e55e27a36dbaaec9d74f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense, LSTM, Input, Bidirectional, TimeDistributed, Embedding, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras_crf import CRFModel\n",
        "from seqeval.metrics import f1_score, classification_report"
      ],
      "metadata": {
        "id": "Ij4Y2mjgbiBU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 128\n",
        "hidden_units = 64\n",
        "dropout_ratio = 0.3"
      ],
      "metadata": {
        "id": "s9xMmmZHfXGy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_input = Input(shape=(max_len,), dtype=tf.int32, name=\"sequence_input\")\n",
        "hidden = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len)(sequence_input)\n",
        "hidden = Bidirectional(LSTM(units=hidden_units, return_sequences=True))(hidden)\n",
        "hidden = TimeDistributed(Dropout(dropout_ratio))(hidden)\n",
        "BiLSTM_ouputs = TimeDistributed(Dense(tag_size, activation='relu'))(hidden)\n",
        "base = Model(sequence_input, BiLSTM_ouputs)\n",
        "model = CRFModel(base, tag_size)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Nadam(0.001), metrics=\"accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvzTkn3ngGjM",
        "outputId": "6b407130-ca71-4545-b22a-79426fa2030e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=4)\n",
        "mc = ModelCheckpoint(\"/content/drive/MyDrive/GitHub/Study-Deeplearning-NLP/Models/BiLSTM_CRF.ckpt\", monitor=\"val_decode_sequence_accuracy\", mode=\"max\", verbose=1, save_best_only=True, save_weights_only=True)"
      ],
      "metadata": {
        "id": "dIi3Fl_EhzFW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train_int, batch_size=128, epochs=15, validation_split=0.1, callbacks=[mc, es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hY45qZVhyvFt",
        "outputId": "fa2c2d6c-31e9-4705-d692-0fea1e9fb9ad"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9096 - loss: 29.2804\n",
            "Epoch 1: val_decode_sequence_accuracy improved from -inf to 0.96019, saving model to /content/drive/MyDrive/GitHub/Study-Deeplearning-NLP/Models/BiLSTM_CRF.ckpt\n",
            "270/270 [==============================] - 89s 266ms/step - decode_sequence_accuracy: 0.9096 - loss: 29.2104 - val_decode_sequence_accuracy: 0.9602 - val_loss: 9.7232\n",
            "Epoch 2/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9708 - loss: 6.7673\n",
            "Epoch 2: val_decode_sequence_accuracy improved from 0.96019 to 0.98047, saving model to /content/drive/MyDrive/GitHub/Study-Deeplearning-NLP/Models/BiLSTM_CRF.ckpt\n",
            "270/270 [==============================] - 49s 182ms/step - decode_sequence_accuracy: 0.9708 - loss: 6.7591 - val_decode_sequence_accuracy: 0.9805 - val_loss: 5.2175\n",
            "Epoch 3/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9824 - loss: 3.9013\n",
            "Epoch 3: val_decode_sequence_accuracy improved from 0.98047 to 0.98452, saving model to /content/drive/MyDrive/GitHub/Study-Deeplearning-NLP/Models/BiLSTM_CRF.ckpt\n",
            "270/270 [==============================] - 56s 209ms/step - decode_sequence_accuracy: 0.9824 - loss: 3.8995 - val_decode_sequence_accuracy: 0.9845 - val_loss: 3.7851\n",
            "Epoch 4/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9866 - loss: 2.7154\n",
            "Epoch 4: val_decode_sequence_accuracy improved from 0.98452 to 0.98548, saving model to /content/drive/MyDrive/GitHub/Study-Deeplearning-NLP/Models/BiLSTM_CRF.ckpt\n",
            "270/270 [==============================] - 45s 167ms/step - decode_sequence_accuracy: 0.9866 - loss: 2.7144 - val_decode_sequence_accuracy: 0.9855 - val_loss: 3.2040\n",
            "Epoch 5/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9885 - loss: 2.1305\n",
            "Epoch 5: val_decode_sequence_accuracy improved from 0.98548 to 0.98588, saving model to /content/drive/MyDrive/GitHub/Study-Deeplearning-NLP/Models/BiLSTM_CRF.ckpt\n",
            "270/270 [==============================] - 47s 175ms/step - decode_sequence_accuracy: 0.9885 - loss: 2.1300 - val_decode_sequence_accuracy: 0.9859 - val_loss: 3.1114\n",
            "Epoch 6/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9898 - loss: 1.7801\n",
            "Epoch 6: val_decode_sequence_accuracy improved from 0.98588 to 0.98599, saving model to /content/drive/MyDrive/GitHub/Study-Deeplearning-NLP/Models/BiLSTM_CRF.ckpt\n",
            "270/270 [==============================] - 45s 165ms/step - decode_sequence_accuracy: 0.9898 - loss: 1.7790 - val_decode_sequence_accuracy: 0.9860 - val_loss: 3.1106\n",
            "Epoch 7/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9907 - loss: 1.5432\n",
            "Epoch 7: val_decode_sequence_accuracy did not improve from 0.98599\n",
            "270/270 [==============================] - 43s 161ms/step - decode_sequence_accuracy: 0.9907 - loss: 1.5423 - val_decode_sequence_accuracy: 0.9860 - val_loss: 3.0298\n",
            "Epoch 8/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9914 - loss: 1.3581\n",
            "Epoch 8: val_decode_sequence_accuracy did not improve from 0.98599\n",
            "270/270 [==============================] - 44s 163ms/step - decode_sequence_accuracy: 0.9914 - loss: 1.3574 - val_decode_sequence_accuracy: 0.9858 - val_loss: 3.0767\n",
            "Epoch 9/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9921 - loss: 1.2033\n",
            "Epoch 9: val_decode_sequence_accuracy did not improve from 0.98599\n",
            "270/270 [==============================] - 44s 163ms/step - decode_sequence_accuracy: 0.9921 - loss: 1.2038 - val_decode_sequence_accuracy: 0.9856 - val_loss: 3.2831\n",
            "Epoch 10/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9926 - loss: 1.0741\n",
            "Epoch 10: val_decode_sequence_accuracy did not improve from 0.98599\n",
            "270/270 [==============================] - 44s 162ms/step - decode_sequence_accuracy: 0.9926 - loss: 1.0741 - val_decode_sequence_accuracy: 0.9855 - val_loss: 3.3601\n",
            "Epoch 11/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9931 - loss: 0.9618\n",
            "Epoch 11: val_decode_sequence_accuracy did not improve from 0.98599\n",
            "270/270 [==============================] - 43s 159ms/step - decode_sequence_accuracy: 0.9931 - loss: 0.9624 - val_decode_sequence_accuracy: 0.9849 - val_loss: 3.3725\n",
            "Epoch 11: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gUIy1bkCy8Bi"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}